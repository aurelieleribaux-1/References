@book{vanderAalstWilM.P2016PMDS,
abstract = {The first to cover this missing link between data mining and process modeling, this book provides real-world techniques for monitoring and analyzing processes in real time. It is a powerful new tool destined to play a key role in business process management.},
author = {van der Aalst, Wil M. P},
address = {Berlin, Heidelberg},
copyright = {Springer-Verlag Berlin Heidelberg 2016},
edition = {2nd ed. 2016 edition.},
isbn = {9783662498507},
keywords = {Computer science ; Computer software ; Information organization ; Information retrieval ; Information storage and retrieval systems ; Software engineering},
language = {eng},
publisher = {Springer Berlin / Heidelberg},
title = {Process Mining: Data Science in Action},
year = {2016},
}


@inproceedings{inproceedings,
author = {Ziolkowski, Tobias and Koschmider, Agnes and Schubert, René and Renz, Matthias},
year = {2022},
month = {06},
title = {Process Mining for Time Series Data}
}

@Inbook{vanderAalst2022,
author="van der Aalst, Wil M. P.",
editor="van der Aalst, Wil M. P.
and Carmona, Josep",
title="Process Mining: A 360 Degree Overview",
bookTitle="Process Mining Handbook",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="3--34",
abstract="Process mining enables organizations to uncover their actual processes, provide insights, diagnose problems, and automatically trigger corrective actions. Process mining is an emerging scientific discipline positioned at the intersection between process science and data science. The combination of process modeling and analysis with the event data present in today's information systems provides new means to tackle compliance and performance problems. This chapter provides an overview of the field of process mining introducing the different types of process mining (e.g., process discovery and conformance checking) and the basic ingredients, i.e., process models and event data. To prepare for later chapters, event logs are introduced in detail (including pointers to standards for event data such as XES and OCEL). Moreover, a brief overview of process mining applications and software is given.",
isbn="978-3-031-08848-3",
doi="10.1007/978-3-031-08848-3_1",
url="https://doi.org/10.1007/978-3-031-08848-3_1"
}

@article{VitaleFrancesco2023APMu,
author = {Vitale, Francesco and De Vita, Fabrizio and Mazzocca, Nicola and Bruneo, Dario},
address = {AMSTERDAM},
copyright = {Copyright 2023 Elsevier B.V., All rights reserved.},
issn = {2542-6605},
journal = {Internet of things},
keywords = {Computer science ; Engineering ; Technology ; Telecommunication ; Time Factors},
language = {eng},
pages = {100993-},
publisher = {Elsevier},
title = {A Process Mining-based unsupervised Anomaly Detection technique for the Industrial Internet of Things},
volume = {24},
year = {2023},
}

@inproceedings{BanhamAdam2022xAFf,
author = {Banham, Adam and Leemans, Sander J.J. and Wynn, Moe T. and Andrews, Robert},
booktitle = {Lecture Notes in Business Information Processing},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
isbn = {9783030985806},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {85-97},
publisher = {Springer Science+Business Media},
title = {xPM: A Framework for Process Mining with Exogenous Data},
volume = {433},
year = {2022},
}

@incollection{TavazziErica2021APMA,
abstract = {Thanks to its ability to offer a time-oriented perspective on the clinical events that define the patient’s path of care, Process Mining (PM) is assuming an emerging role in clinical data analytics. PM’s ability to exploit time-series data and to build processes without any a priori knowledge suggests interesting synergies with the most common statistical analyses in healthcare, in particular survival analysis. In this work we demonstrate contributions of our process-oriented approach in analyzing a real-world retrospective dataset of patients treated for advanced melanoma at the Lausanne University Hospital. Addressing the clinical questions raised by our oncologists, we integrated PM in almost all the steps of a common statistical analysis. We show: (1) how PM can be leveraged to improve the quality of the data (data cleaning/pre-processing), (2) how PM can provide efficient data visualizations that support and/or suggest clinical hypotheses, also allowing to check the consistency between real and expected processes (descriptive statistics), and (3) how PM can assist in querying or re-expressing the data in terms of pre-defined reference workflows for testing survival differences among sub-cohorts (statistical inference). We exploit a rich set of PM tools for querying the event logs, inspecting the processes using statistical hypothesis testing, and performing conformance checking analyses to identify patterns in patient clinical paths and study the effects of different treatment sequences in our cohort.},
author = {Tavazzi, Erica and Gerard, Camille L. and Michielin, Olivier and Wicky, Alexandre and Gatta, Roberto and Cuendet, Michel A.},
address = {Cham},
booktitle = {Process Mining Workshops},
copyright = {The Author(s) 2021, Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.},
isbn = {9783030726928},
issn = {1865-1348},
keywords = {Melanoma ; Oncology ; Process mining ; Statistics},
language = {eng},
pages = {291-304},
publisher = {Springer International Publishing},
series = {Lecture Notes in Business Information Processing},
title = {A Process Mining Approach to Statistical Analysis: Application to a Real-World Advanced Melanoma Dataset},
volume = {406},
year = {2021},
}

@article{KobialkaPaul2024Ujga,
abstract = {The servitization of business is moving industry to business models driven by customer demand. Customer satisfaction is connected with financial rewards, forcing companies to invest in their users’ experience. User journeys describe how users maneuver through a service. Today, user journeys are typically modeled graphically, and lack formalization and analysis support. This paper proposes a formalization of user journeys as weighted games between the user and the service provider and a systematic data-driven method to derive these user journey games from system logs, using process mining techniques. As the derived games may contain cycles, we define an algorithm to transform user journeys games with cycles into acyclic weighted games, which can be model checked using
to uncover potential challenges in a company’s interactions with its users and derive company strategies to guide users through their journeys. Finally, we propose a user journey sliding-window analysis to detect changes in the user journey over time by model checking a sequence of generated games. Our analysis pipeline has been evaluated on an industrial case study; it revealed design challenges within the studied service and could be used to derive actionable recommendations for improvement.},
author = {Kobialka, Paul and Lizeth Tapia Tarifa, S. and Bergersen, Gunnar R. and Johnsen, Einar Broch},
address = {Berlin/Heidelberg},
copyright = {The Author(s) 2024},
issn = {1619-1366},
journal = {Software and systems modeling},
keywords = {Algorithms ; Automation ; Case studies ; Computer science ; Computer software ; Consumer satisfaction ; Customer services ; Games ; Pipelines ; Software engineering ; Technology ; Time-series analysis ; Translators},
language = {eng},
number = {3},
pages = {605-624},
publisher = {Springer Berlin Heidelberg},
title = {User journey games: automating user-centric analysis},
volume = {23},
year = {2024},
}

@article{PanYue2021ABmi,
abstract = {With the focus of smart construction project management, this paper presents a closed-loop digital twin framework under the integration of Building Information Modeling (BIM), Internet of Things (IoT), and data mining (DM) techniques. To be specific, IoT connects the physical and cyber world to capture real-time data for modeling and analyzing, and data mining methods incorporated in the virtual model aim to discover hidden knowledge in collected data. The proposed digital twin has been verified in a practical BIM-based project. Based on large inspection data from IoT devices, the 4D visualization and task-centered or worker-centered process model are built as the virtual model to simulate both the task execution and worker cooperation. Then, the high-fidelity virtual model is investigated by process mining and time series analysis. Results show that possible bottlenecks in the current process can be foreseen using the fuzzy miner, while the number of finished tasks in the next phase can be predicted by the multivariate autoregressive integrated moving average (ARIMAX) model. Consequently, tactic decision-making can realize to not only prevent possible failure in advance, but also arrange work and staffing reasonably to make the process adapt to changeable conditions. In short, the significance of this paper is to build a data-driven digital twin framework integrating with BIM, IoT, and data mining for advanced project management, which can facilitate data communication and exploration to better understand, predict, and optimize the physical construction operations. In future works, more complex cases with multiple data streams will be used to test the developed framework, and more detailed interpretations with the actual observations of construction activities will be given.
•A closed-loop digital twin framework integrating BIM and process mining is proposed.•Volumes of event log data generated daily in the real process are transmitted to the virtual model.•It can display promising performance in discovering hidden knowledge in large inspection data.•Possible bottlenecks in the current process can be captured based on the fuzzy miner.•Time series prediction model is performed to foresee variation trend of construction productivity.},
author = {Pan, Yue and Zhang, Limao},
address = {AMSTERDAM},
copyright = {2021 Elsevier B.V.},
issn = {0926-5805},
journal = {Automation in construction},
keywords = {Building information modeling ; Construction ; Data Analysis ; Data Collection ; Data mining ; Decision making ; Digital media ; Electronic apparatus and appliances ; Engineering ; Inspection ; Internet of things ; Modeling ; Process mining ; Project management ; Technology ; Time Factors},
language = {eng},
pages = {103564-},
publisher = {Elsevier B.V},
title = {A BIM-data mining integrated digital twin framework for advanced project management},
volume = {124},
year = {2021},
}

@inproceedings{SoltiAndreas2017TSPN,
abstract = {Operational support as an area of process mining aims to predict the performance of individual cases and the overall business process. Although seasonal effects, delays and performance trends are well-known to exist for business processes, there is up until now no prediction model available that explicitly captures seasonality. In this paper, we introduce time series Petri net models. These models integrate the control flow perspective of Petri nets with time series prediction. Our evaluation on the basis of our prototypical implementation demonstrates the merits of this model in terms of better accuracy in the presence of time series effects.},
author = {Solti, Andreas and Vana, Laura and Mendling, Jan},
address = {Cham},
booktitle = {Data-Driven Process Discovery and Analysis},
copyright = {IFIP International Federation for Information Processing 2017},
isbn = {9783319534343},
issn = {1865-1348},
keywords = {Business intelligence ; Petri nets ; Predictive analytics ; Time Factors},
language = {eng},
pages = {124-141},
publisher = {Springer International Publishing},
title = {Time Series Petri Net Models: Enrichment and Prediction},
volume = {244},
year = {2017},
}

@article{RashidMuhammad2017AMPM,
abstract = {Cost, time and resources are major factors affecting the quality of hospitals business processes. Bio-medical processes are twisted, unstructured and based on time series making it difficult to do proper process modeling for them. On other hand, Process mining can be used to provide an accurate view of biomedical processes and their execution. Extracting process models from biomedical code sequenced data logs is a big challenge for process mining as it doesn’t provide business entities for workflow modeling. This paper explores application of process mining in biomedical domain through real-time case study of hepatitis patients. To generate event logs from big datasets, preprocessing techniques and LOG Generator tool is designed. To reduce complexity of generated process model, a multilevel process mining framework including text similarity clustering algorithm based on Levenshtein Distance is proposed for event logs to eliminate spaghetti processes. Social network models and four distinct types of sub workflow models are evaluated using specific process mining algorithms.},
author = {Rashid, Muhammad and Naeem, Hamad and Aamir, Muhammad and Ali, Waqar and Ahmed, Waheed},
address = {West Yorkshire},
copyright = {2017. This work is licensed under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2158-107X},
journal = {International journal of advanced computer science & applications},
keywords = {Algorithms ; Big data ; Bioinformatics ; Cluster analysis ; Computer science ; Knowledge management ; Modeling ; Patients ; Social networks ; Software ; Time Factors ; Workflow},
language = {eng},
number = {3},
publisher = {Science and Information (SAI) Organization Limited},
title = {A Multi-Level Process Mining Framework for Correlating and Clustering of Biomedical Activities using Event Logs},
volume = {8},
year = {2017},
}

@inproceedings{WenanTan2016Hhmb,
abstract = {To cope with time-attribute and variations of event distribution in dynamic evolving process, an streaming process mining based on time series prediction and hybrid heuristic miner is proposed. A heuristic miner is improved based on post-task of activity in event logs to optimize the initial particle distribution for Particle Swarm Optimization. Furthermore, "aging factor" based on time series attribute is also designed for adaptive global optimization. Besides, time-related Process Decision Indicator(PDI) is defined as a pattern observable to identify domain-independent evolution indicators in process model. The experimental results show that our algorithm is more effective and scalable for streaming process mining.},
author = {Wenan Tan and Li Huang and Tengteng Shen and Anqiong Tang},
booktitle = {2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)},
isbn = {9781509019151},
keywords = {Aging ; Data mining ; Heuristic algorithms ; Process mining},
language = {eng},
pages = {251-256},
publisher = {IEEE},
title = {Hybrid heuristics miner based on time series prediction for streaming process mining},
year = {2016},
}

@incollection{ValdésJulioJ.2021PMCE,
abstract = {This paper presents two approaches for using Process Mining to the analysis of time series. They are applied to a time series of Meteosat full-disk water-vapor satellite images characterized by their pairwise similarity. Event logs constructed from this time series are processed with the Inductive Miner algorithm producing models in the form of Petri Nets and Directly-Follows Graphs (DFG). In the first approach, logs corresponding to five years of similarity indexes of daily images were grouped by astronomical seasons and Petri Nets models were discovered for each season. From them, trace fitness obtained with token-based replay conformance checking were used as features for characterizing the logs, and supervised machine learning algorithms were applied to obtain classification models. In the second approach, Gram matrices using different graph kernels were computed from the individual DFGs associated to each log, and used by support vector machines for constructing classification models. For all seasons, high-performance models were found, matching those obtained with state-of-the-art techniques, with the plus of providing a description of the time series data structure, demonstrating the potential of PM-based approaches. The analysis revealed the presence of some consistent miss-classification patterns that could be related to the ongoing process of climate change. The results obtained are preliminary and open interesting research directions.},
author = {Valdés, Julio J. and Pou, Antonio and Céspedes-González, Yaimara},
address = {Switzerland},
booktitle = {Lecture Notes in Networks and Systems},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {9783030899059},
issn = {2367-3370},
keywords = {Process mining ; Time Factors},
language = {eng},
pages = {650-667},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Process Mining Capabilities Extended to Time Series Analysis as Applied to Meteosat Water Vapor Images},
volume = {358},
year = {2021},
}

@inproceedings{SuZihang2023DGRi,
abstract = {A transhumeral prosthesis restores missing anatomical segments below the shoulder, including the hand. Active prostheses utilize real-valued, continuous sensor data to recognize patient target poses, or goals, and proactively move the artificial limb. Previous studies have examined how well the data collected in stationary poses, without considering the time steps, can help discriminate the goals. In this case study paper, we focus on using time series data from surface electromyography electrodes and kinematic sensors to sequentially recognize patients' goals. Our approach involves transforming the data into discrete events and training an existing process mining-based goal recognition system. Results from data collected in a virtual reality setting with ten subjects demonstrate the effectiveness of our proposed goal recognition approach, which achieves significantly better precision and recall than the state-of-the-art machine learning techniques and is less confident when wrong, which is beneficial when approximating smoother movements of prostheses.},
author = {Su, Zihang and Yu, Tianshi and Lipovetzky, Nir and Mohammadi, Alireza and Oetomo, Denny and Polyvyanyy, Artem and Sardina, Sebastian and Tan, Ying and van Beest, Nick},
booktitle = {2023 5th International Conference on Process Mining (ICPM)},
isbn = {9798350358391},
keywords = {Artificial limbs ; Machine learning ; Process mining ; Training ; Virtual reality},
language = {eng},
pages = {25-32},
publisher = {IEEE},
title = {Data-Driven Goal Recognition in Transhumeral Prostheses Using Process Mining Techniques},
year = {2023},
}

@article{AdamsJanNiklas2023Ecdi,
abstract = {The execution of processes leaves trails of event data in information systems. These event data are analyzed to generate insights and improvements for the underlying process. However, companies do not execute these processes in a vacuum. The fast pace of technological development, constantly changing market environments, and fast consumer responses expose companies to high levels of uncertainty. This uncertainty often manifests itself in significant changes in the executed processes. Such significant changes are called concept drifts. Transparency about concept drifts is crucial to respond quickly and adequately, limiting the potentially negative impact of such drifts. Three types of knowledge are of interest to a process owner: When did a drift occur, what happened, and why did it happen. This paper introduces a framework to extract concept drifts and their potential root causes from event data. We extract time series describing process measures, detect concept drifts, and test these drifts for correlation. This framework generalizes existing work such that object-centric event data with multiple case notions, non-linear relationships, and an arbitrary number of process measures are supported. We provide an extendable implementation and evaluate our framework concerning the sensitivity of the time series construction and scalability of cause–effect testing. Furthermore, we provide a case study uncovering an explainable concept drift.
[Display omitted]
•We propose a data-driven approach to uncover explanations for process concept drifts.•The proposed technique detects and explains drifts for object-centric event data.•Our framework supports linear and non-linear relationships.},
author = {Adams, Jan Niklas and van Zelst, Sebastiaan J. and Rose, Thomas and van der Aalst, Wil M.P.},
address = {OXFORD},
copyright = {2023 Elsevier Ltd},
issn = {0306-4379},
journal = {Information systems (Oxford)},
keywords = {Computer science ; Process mining ; Technology},
language = {eng},
pages = {102177-},
publisher = {Elsevier Ltd},
title = {Explainable concept drift in process mining},
volume = {114},
year = {2023},
}

@inproceedings{SchroerChristoph2024DtSP,
abstract = {Numerous data-driven approaches made their way into the strategic decision-making process for identifying companies for strategic partnerships or M&A-activities. While the data availability such as of financials of global player is given sufficiently, it's not for start-ups. However, start-ups occupy a high potential in terms of growing yields. In contrast, only 10 % of European start-ups survive their first seven years. To overcome the lack of data to evaluate start-ups, we process key developments sourced by S&P. Key developments are daily-based events such as private placements or product announcements. We preprocess time-series of key developments for around 76,600 global start-ups acting in 5 different industries. Based on criteria derived from the reference literature, we divided start-ups into less or more successful companies to train several models by using the process mining algorithms alpha, heuristic and inductive miner in combination with classification algorithms like XGBoost, support vector machine and decision tree to classify a start-up' performance. In doing so, we significantly identify processes of successful start-ups. Beside theoretical implications regarding the application of algorithms on key developments, our approach addresses managerial implications by supporting at finding high potential start-ups to enlarge business opportunities as well as for minimizing risks deriving from unprofitable investments.},
author = {Schroer, Christoph and Wittfoth, Sven and Hullen, Tabea and Naumann, Florian and Frischkorn, Jonas and Muller-Pietralla, Wolfgang},
booktitle = {2024 Portland International Conference on Management of Engineering and Technology (PICMET)},
isbn = {1890843458},
keywords = {Business enterprises ; Decision making ; Europe ; Heuristic algorithms ; Industries ; Process mining ; Support vector machines},
language = {eng},
pages = {1-14},
publisher = {PICMET},
title = {Decrypting the Success Path of High Potential Start-ups: The Application of Process Mining Algorithms on Key Developments},
year = {2024},
}

@incollection{ValdésJulioJ.2021PMaa,
abstract = {Process Mining (PM) approaches for the analysis of time series bring interesting new perspectives because of the structural and behavioral information that could be extracted when the series are represented as event logs. This paper presents a Process Mining-based, supervised machine learning approach for constructing time series classifiers using graph kernels. A collection of time series of different kinds (normal, cyclic, with upward/downward trends and with upward/downward level shifts) is pre-processed by converting the real-valued series into event logs. Directly Follows Graphs (DFG) for activities and resources were discovered using the Inductive Miner algorithm and eight graph kernels were used for evaluating the similarities between the DFGs. These kernels were used in conjunction with class membership information for obtaining classification models in the form of support vector machines. High-performance classification models were found, particularly when using additively aggregated kernels coming from the combination of those obtained separately from activities and resources. The PM-based models have cross-validation mean accuracies comparable with those based on dynamic time warping, as well as top precision and recall metrics for most of the graph kernels. The results obtained are preliminary, but illustrate the potential of PM methods for time series analysis.},
author = {Valdés, Julio J. and Céspedes-González, Yaimara and Pou, Antonio},
address = {Switzerland},
booktitle = {Lecture Notes in Networks and Systems},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {9783030899059},
issn = {2367-3370},
keywords = {Machine learning ; Process mining ; Time Factors},
language = {eng},
pages = {832-847},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Process Mining as a Time Series Analysis Tool via Graph Kernels},
volume = {358},
year = {2021},
}

@incollection{ValdésJulioJ.2021PMaa,
abstract = {This paper presents a novel approach for the analysis of time series, using Process Mining conformance checking measures as features describing the series’ models, in conjunction with machine learning techniques. The presented approach aims at identifying classes of time series based on their structure content and behavior (normal series, cycles, trends and changes of level). Event logs constructed from time series of different kinds are processed with the Inductive Miner algorithm, producing Petri Nets models. The resulting models are used for creating sets of features for individual time series logs, using trace-fitness measures. These measures are obtained with token-based replay conformance checking. An assessment of the predictive potential of these features is obtained with the Gamma Test, and a collection of supervised machine learning techniques is used for constructing classification models. For some classes, high performance models were found, demonstrating the potential of the proposed approach. However, there were classes for which the Petri Net models produced by the Inductive Miner algorithm did not produce token-based replay conformance checking features with enough predictive power. Overall, Process Mining-based time series classification using conformance checking proved to be a valuable tool. The results obtained are encouraging, but preliminary, and open several avenues to investigate.},
author = {Valdés, Julio J. and Céspedes-González, Yaimara and Pou, Antonio},
address = {Switzerland},
booktitle = {Lecture Notes in Networks and Systems},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {9783030899059},
issn = {2367-3370},
keywords = {Machine learning ; Process mining ; Time Factors},
language = {eng},
pages = {636-649},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Process Mining as a Time Series Analysis Tool via Conformance Checking},
volume = {358},
year = {2021},
}

@article{ShiYilin2024Nafi,
abstract = {Anomaly detection plays a critical role in ensuring the quality and safety of industrial processes. Process mining, as an emerging technology, has proven effective in extracting knowledge and process rules inherent in process events. However, industrial time series data possess characteristics such as high noise, and data redundancy, posing challenges for accurately assessing system anomalies using traditional data-driven methods. To address these challenges, this paper proposes a Trend-Value Fusion Process Mining (TVPM) approach based on the representation of industrial process events to tackle anomaly detection in industrial processes. Firstly, TVPM introduces a fusion measure that combines data trends and mean-value to provide a comprehensive description of operating events in industrial processes. This fusion measure serves as a vital tool for capturing the complex details and features of industrial events. Additionally, a novel process discovery algorithm is developed to extract behavioral patterns and sequence information from events. Finally, a process abnormal state detection model is constructed by leveraging the comprehensive and in-depth information obtained from TVPM. The proposed method is applied to an industrial coal gasification process, yielding satisfactory results.
•An approach to TVPM of industrial process operating events for abnormal detection was proposed.•This paper introduced a method for extracting process event constructs that blend value and trend information.•The final process abnormal detection framework was applied to an actual industrial process.},
author = {Shi, Yilin and Zhang, Ning and Song, Xiaolu and Li, Hongguang and Zhu, Qunxiong},
address = {London},
copyright = {2024 Elsevier Ltd},
issn = {0959-1524},
journal = {Journal of process control},
keywords = {Chemical engineering ; Engineering ; Process mining ; Technology},
language = {eng},
pages = {103165-},
publisher = {Elsevier Ltd},
title = {Novel approach for industrial process anomaly detection based on process mining},
volume = {136},
year = {2024},
}

@inproceedings{Fernández-LlatasCarlos2014Tate,
abstract = {The design of clinical protocols for improving the quality of care in an efficient way is one of the challenges for the deployment of Evidence Based Medicine. The design of those protocols is a difficult task that require the consensus of care process experts. The use of Pattern Recognition approaches, like Process Mining, allows the automatic inference of processes that can help experts for formalizing these clinical protocols based on the actually deployed care process. However, the step rules among the different stages of the care protocols are based on high level descriptions of numerical clinical data gathered from the patient that can not be processed directly by Process Mining approaches. In this paper, a combination of Interactive Pattern Recognition with Temporal Abstraction technologies that allows processing of clinical data to allow the enrichment of Activity Based Process Mining corpus is presented.},
author = {Fernández-Llatas, Carlos and Sacchi, Lucia and Benedí, José Miguel and Dagliati, Arianna and Traver, Vicente and Bellazzi, Riccardo},
booktitle = {IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)},
isbn = {1479921319},
issn = {2168-2194},
keywords = {Data mining ; Marketing research ; Medical care ; Process control},
language = {eng},
pages = {785-788},
publisher = {IEEE},
title = {Temporal abstractions to enrich Activity-Based Process Mining corpus with clinical time series},
year = {2014},
}

@incollection{PourbafraniMahsa2020STDf,
abstract = {Most information systems supporting operational processes also record event logs. These can be used to diagnose performance and compliance problems. The majority of process mining techniques extract models that are descriptive and describe what happened in the past. Few process mining techniques discover models that allow us to “look into the future” and perform predictive analyses. Recently, novel approaches have been developed for scenario-based prediction, i.e., predicting the effects of process changes on process performance, e.g., investing in an additional resource. To work accurately, the techniques need an appropriate time step-size, the selection of which, thus far, has been an ad-hoc and manual endeavor. Therefore, in this paper, building upon time-series analysis and forecasting techniques, we propose a novel semi-automated time-granularity detection framework. Our framework detects the best possible time-granularity to be used, whilst taking user preferences into account. Our evaluation, using both real and synthetic data, confirms the feasibility of our approach and highlights the importance of using accurate granularity in time step selection.},
author = {Pourbafrani, Mahsa and van Zelst, Sebastiaan J. and van der Aalst, Wil M. P. and Mayr, Heinrich C and Liddle, Stephen W and Kappel, Gerti and Frank, Ulrich and Dobbie, Gillian and Liddle, Stephen W. and Kappel, Gerti and Mayr, Heinrich C. and Dobbie, Gillian and Frank, Ulrich},
address = {Switzerland},
booktitle = {Conceptual Modeling},
copyright = {Springer Nature Switzerland AG 2020},
isbn = {9783030625214},
issn = {0302-9743},
keywords = {Process mining ; Time-series analysis},
language = {eng},
pages = {77-91},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Semi-automated Time-Granularity Detection for Data-Driven Simulation Using Process Mining and System Dynamics},
volume = {12400},
year = {2020},
}

@article{RuschelEdson2020Eomi,
abstract = {Reducing costs and increasing equipment availability (uptime) are among the main goals of industrial ventures. Well defined interval durations between maintenance inspections provide major support in achieving these targets. However, in order to establish the best interval length, process behavior, cycle times and related costs must be clearly known, and future estimates for these parameters must be established. This paper applies process mining techniques in developing a probabilistic model in Bayesian Networks integrated to predictive models. The probability of a given activity occurring in the probabilistic model output establishes the forecast boundaries for predictive models, responsible for estimating process cycle times. Availability (uptime) and cost functions are mathematically defined and an iterative process is performed in the length of intervals between maintenance inspections until the time and costs wasted are minimized and the best interval duration is found. The probabilistic model enables simulating changes in the event occurrence probability, allowing a number of different scenarios to be visualized and providing better support to managers in scheduling maintenance activities. The results show that production losses can be further reduced through optimally defined intervals between maintenance inspections.},
author = {Ruschel, Edson and Santos, Eduardo Alves Portela and Loures, Eduardo de Freitas Rocha},
address = {New York},
copyright = {Springer Science+Business Media, LLC, part of Springer Nature 2018},
issn = {0956-5515},
journal = {Journal of intelligent manufacturing},
keywords = {Bayesian statistical decision theory ; Computer science ; Computer simulation ; Control ; Costs ; Economic forecasting ; Engineering ; Implements ; Inspection ; Machinery ; Maintenance ; Mechatronics ; Models Statistical ; Parameter estimation ; Process mining ; Robotics ; Statistics ; Technology},
language = {eng},
number = {1},
pages = {53-72},
publisher = {Springer US},
title = {Establishment of maintenance inspection intervals: an application of process mining techniques in manufacturing},
volume = {31},
year = {2020},
}

@inproceedings{AdamsJanNiklas2021AFfE,
abstract = {Rapidly changing business environments expose companies to high levels of uncertainty. This uncertainty manifests itself in significant changes that tend to occur over the lifetime of a process and possibly affect its performance. It is important to understand the root causes of such changes since this allows us to react to change or anticipate future changes. Research in process mining has so far only focused on detecting, locating and characterizing significant changes in a
process and not on finding root causes of such changes. In this paper, we aim to close this gap. We propose a framework that adds an explainability level onto concept drift detection in process mining and provides insights into the cause-effect relationships behind significant changes. We define different perspectives of a process, detect concept drifts in these perspectives and plug the perspectives into a causality check that determines whether these concept drifts can be causal to each other. We showcase the effectiveness of our framework by evaluating it on both synthetic and real event data. Our experiments show that our approach unravels cause-effect relationships and provides novel insights into executed processes.},
author = {Adams, Jan Niklas and van Zelst, Sebastiaan J. and Quack, Lara and Hausmann, Kathrin and van der Aalst, Wil M. P. and Rose, Thomas},
address = {Cham},
booktitle = {Business Process Management},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030854683},
issn = {0302-9743},
keywords = {Process mining},
language = {eng},
pages = {400-416},
publisher = {Springer International Publishing},
title = {A Framework for Explainable Concept Drift Detection in Process Mining},
volume = {12875},
year = {2021},
}

@article{HornsteinerMarkus2024RbtL,
abstract = {The introduction of the Industrial Internet of Things (IIoT) has led to major changes in the industry. Thanks to machine data, business process management methods and techniques could also be applied to them. However, one data source has so far remained untouched: The network data of the machines. In the business environment, process mining, for example, has already been carried out based on network data, but the IIoT, with its particular protocols such as OPC UA, has yet to be investigated. With the help of design science research and on the shoulders of CRISP-DM, we first develop a framework for process mining in the IIoT in this paper. We then apply the framework to real-world IIoT network traffic data and evaluate the outcome and performance of our approach in detail. We find tremendous potential in network traffic data but also limitations. Among other things, due to the dependence on process experts and the existence of case IDs.},
author = {Hornsteiner, Markus and Empl, Philip and Bunghardt, Timo and Schoenig, Stefan},
address = {BASEL},
copyright = {2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
keywords = {Algorithms ; Automation ; Chemistry ; Communication ; Data mining ; Decision making ; Engineering ; Industry 4.0 ; Machine learning ; Physical sciences ; Process mining ; Technology},
language = {eng},
number = {14},
pages = {4497-},
publisher = {Mdpi},
title = {Reading between the Lines: Process Mining on OPC UA Network Data},
volume = {24},
year = {2024},
}

@article{DoganOnur2024EMEw,
abstract = {The production of high-quality products and efficient manufacturing processes in modern environments, where processes vary widely, is one of the most crucial issues today. Statistical process control (SPC) and process mining (PM) effectively trace and enhance the manufacturing processes. In this direction, this paper proposes an innovative approach involving SPC and PM strategies to empower the manufacturing environment. SPC monitors key performance indicators (KPIs) and identifies out-of-control processes that deviate from specification limits, while PM discovery techniques are applied for those abnormal processes to extract the actual process flow from event logs and model it using Petri nets. Different enhancement techniques in PM, such as decision rules and root cause analysis, are then used to return the process to control and prevent future deviations. The application of the integrated SPC-PM approach is shown through case studies of production processes. SPC charts found that over 6% of processes exceeded specification limits. At the same time, PM methodologies revealed that prolonged times for the 'Quality Control' activity is the fundamental factor increasing the cycle time. Moreover, decision tree analysis provides rules for decreasing the cycle times of unbalanced processes. The absence of a transition from the 'Return from Waiting' activity to 'Packing and Shipment' is a critical factor in decreasing cycle times, as is the shift information. Our newly proposed methodology, which combines process analysis from PM with statistical monitoring from SPC, ensures operational excellence and consistent quality in manufacturing. This study illustrates the application of the proposed methodology through a case study in production processes, highlighting its effectiveness in identifying and addressing process deviations.},
author = {Dogan, Onur and Areta Hiziroglu, Ourania},
address = {BASEL},
copyright = {COPYRIGHT 2024 MDPI AG},
issn = {2075-1702},
journal = {Machines},
keywords = {Data mining ; Data processing ; Decision trees ; Efficiency ; Engineering ; Information resources management ; Manufacturing industries ; Manufacturing processes ; Mechanical engineering ; Mechanics Applied ; Petri nets ; Power (Social sciences) ; Process mining ; Quality control ; Quality of products ; Root cause analysis ; Specifications ; Technology},
language = {eng},
number = {6},
pages = {411-},
publisher = {Mdpi},
title = {Empowering Manufacturing Environments with Process Mining-Based Statistical Process Control},
volume = {12},
year = {2024},
}

@article{RosaAngelo2024PMO(,
abstract = {This paper discusses a methodology to improve the prevention processes of chronic diseases such as diabetes and strokes. The research motivation is to find a new methodological approach to design advanced Diagnostic and Therapeutic Care Pathways (PDTAs) based on the prediction of chronic disease using telemedicine technologies and machine learning (ML) data processing techniques. The aim is to decrease health risk and avoid hospitalizations through prevention. The proposed method defines a Process Mining Organization (PMO) model, managing risks using a PDTA structured to prevent chronic risk. Specifically, the data analysis is focused on stroke risk. First, we applied and compared the Random Forest (RF) and Gradient Boosted Trees (GBT) supervised algorithms to predict stroke risk, and then, the Fuzzy c-Means unsupervised algorithm to cluster information on the predicted results. The application of the proposed approach is able to increase the efficiency of healthcare human resources and drastically decrease care costs.},
author = {Rosa, Angelo and Massaro, Alessandro},
address = {Basel},
copyright = {Copyright 2024 Elsevier B.V., All rights reserved.},
issn = {2673-4117},
journal = {Eng},
keywords = {Algorithms ; Chronic diseases ; Data Analysis ; Data processing ; Decision making ; Decision trees ; Diabetes ; Heart ; Hypertension ; Machine learning ; Medicine Preventive ; Patients ; Process mining ; Stroke ; Telecommunication in medicine},
language = {eng},
number = {1},
pages = {282-300},
publisher = {MDPI AG},
title = {Process Mining Organization (PMO) Based on Machine Learning Decision Making for Prevention of Chronic Diseases},
volume = {5},
year = {2024},
}

@article{YardleyElizabeth2024DEoN,
abstract = {Background: The National Health Service (NHS) Talking Therapies program treats people with common mental health problems in England according to "stepped care," in which lower-intensity interventions are offered in the first instance, where clinically appropriate. Limited resources and pressure to achieve service standards mean that program providers are exploring all opportunities to evaluate and improve the flow of patients through their service. Existing research has found variation in clinical performance and stepped care implementation across sites and has identified associations between service delivery and patient outcomes. Process mining offers a data-driven approach to analyzing and evaluating health care processes and systems, enabling comparison of presumed models of service delivery and their actual implementation in practice. The value and utility of applying process mining to NHS Talking Therapies data for the analysis of care pathways have not been studied. Objective: A better understanding of systems of service delivery will support improvements and planned program expansion. Therefore, this study aims to demonstrate the value and utility of applying process mining to NHS Talking Therapies care pathways using electronic health records. Methods: Routine collection of a wide variety of data regarding activity and patient outcomes underpins the Talking Therapies program. In our study, anonymized individual patient referral records from two sites over a 2-year period were analyzed using process mining to visualize the care pathway process by mapping the care pathway and identifying common pathway routes. Results: Process mining enabled the identification and visualization of patient flows directly from routinely collected data. These visualizations illustrated waiting periods and identified potential bottlenecks, such as the wait for higher-intensity cognitive behavioral therapy (CBT) at site 1. Furthermore, we observed that patients discharged from treatment waiting lists appeared to experience longer wait durations than those who started treatment. Process mining allowed analysis of treatment pathways, showing that patients commonly experienced treatment routes that involved either low- or high-intensity interventions alone. Of the most common routes, >5 times as many patients experienced direct access to high-intensity treatment rather than stepped care. Overall, 3.32% (site 1: 1507/45,401) and 4.19% (site 2: 527/12,590) of all patients experienced stepped care. Conclusions: Our findings demonstrate how process mining can be applied to Talking Therapies care pathways to evaluate pathway performance, explore relationships among performance issues, and highlight systemic issues, such as stepped care being relatively uncommon within a stepped care system. Integration of process mining capability into routine monitoring will enable NHS Talking Therapies service stakeholders to explore such issues from a process perspective. These insights will provide value to services by identifying areas for service improvement, providing evidence for capacity planning decisions, and facilitating better quality analysis into how health systems can affect patient outcomes.},
author = {Yardley, Elizabeth and Davis, Alice and Eldridge, Chris and Vasilakis, Christos},
address = {TORONTO},
copyright = {Elizabeth Yardley, Alice Davis, Chris Eldridge, Christos Vasilakis. Originally published in JMIR Mental Health (https://mental.jmir.org), 21.05.2024.},
issn = {2368-7959},
journal = {JMIR mental health},
keywords = {Algorithms ; Cohort analysis ; Data mining ; Depression Mental ; Electronic Health Records ; England ; Female ; Human beings ; Male ; Medical care ; Mental health ; Mental illness ; Panic attacks ; Panic disorders ; Patients ; Psychiatry ; Psychology Pathological ; Public health ; Retrospective Studies},
language = {eng},
pages = {e53894-e53894},
publisher = {Jmir Publications, Inc},
title = {Data-Driven Exploration of National Health Service Talking Therapies Care Pathways Using Process Mining: Retrospective Cohort Study},
volume = {11},
year = {2024},
}

@incollection{DoganOnur2022UPAP,
abstract = {Especially in people over 50 years of age, sedentary lifestyle can cause muscle loss called sarcopenia. Inactivity causes undesirable outcomes such as excessive weight gain and muscle loss. Weight gain can lead to a variety of problems, including deteriorating of the musculoskeletal system, joint problems, and sleep problems. In order to provide better service, it can be beneficial to understand human behavior in terms of health services. Process mining, which can be considered a part of knowledge graphs, is a crucial methodology for process improvement since it offers a model of the process that can be analyzed and optimized. This study uses process mining approaches to examine data from three patient that were collected using indoor location sensors, allowing the collection of flows of human behavior in the home. The analyses indicated how much time was spent by the patients of the house in each room during the day as well as how frequently they occurred. The movement of patients from room to room was observed daily and subjected to a variety of analyses. With the help of user pathways, lengths of stay in the rooms, and frequency of presence, it has been possible to reveal the details of daily human behavior. Inferences about the habits of the participants were revealed day by day.}, 
author = {Dogan, Onur and Akkol, Ekin and Olucoglu, Muge},
address = {Switzerland},
booktitle = {Communications in Computer and Information Science},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {9783031214219},
issn = {1865-0929},
keywords = {Home automation ; Process mining},
language = {eng},
pages = {298-311},
publisher = {Springer International Publishing AG},
series = {Communications in Computer and Information Science},
title = {Understanding Patient Activity Patterns in Smart Homes with Process Mining},
volume = {1686},
year = {2022},
}

@article{NamakiAraghiSina2024DAIt,
abstract = {The remarkable growth of process mining applications in care pathway monitoring is undeniable. One of the sub-emerging case studies is the use of patients’ location data in process mining analyses. While the streamlining of published works is focused on introducing process discovery algorithms, there is a necessity to address challenges beyond that. Literature analysis indicates that explainability, reasoning, and characterizing the root causes of process drifts in healthcare processes constitute an important but overlooked challenge. In addition, incorporating domain-specific knowledge into process discovery could be a significant contribution to process mining literature. Therefore, we mitigate the issue by introducing cognitive process mining through the DIAG approach, which consists of a meta-model and an algorithm. This approach enables reasoning and diagnosing in process mining through an ontology-driven framework. With DIAG, we modeled the healthcare semantics in a process mining application and diagnosed the causes of drifts in patients’ pathways. We performed an experiment in a hospital living lab to examine the effectiveness of our approach.},
author = {Namaki Araghi, Sina and Fontanili, Franck and Sarkar, Arkopaul and Lamine, Elyes and Karray, Mohamed Hedi and Benaben, Frederick},
address = {Basel},
copyright = {Copyright 2024 Elsevier B.V., All rights reserved.},
issn = {2673-3951},
journal = {Modelling},
keywords = {Algorithms ; Behavior ; Drift ; Medical care ; Ontology ; Patients ; Process mining ; Reasoning ; Research ; Semantics},
language = {eng},
number = {1},
pages = {85-98},
publisher = {MDPI AG},
title = {DIAG Approach: Introducing the Cognitive Process Mining by an Ontology-Driven Approach to Diagnose and Explain Concept Drifts},
volume = {5},
year = {2024},
}

@incollection{MehdiyevNijat2021EAIf,
abstract = {The contemporary process-aware information systems possess the capabilities to record the activities generated during the process execution. To leverage these process specific fine-granular data, process miningProcess mining has recently emerged as a promising research discipline. As an important branch of process miningProcess mining, predictive business process management, pursues the objective to generate forward-looking, predictive insights to shape business processes. In this study, we propose a conceptual framework sought to establish and promote understanding of decision-making environment, underlying business processes and nature of the user characteristics for developing explainable business process prediction solutions. Consequently, with regard to the theoretical and practical implications of the framework, this study proposes a novel local post-hoc explanation approach for a deep learningDeep learning classifier that is expected to facilitate the domain experts in justifying the model decisions. In contrary to alternative popular perturbation-based local explanation approaches, this study defines the local regions from the validation dataset by using the intermediate latent space representations learned by the deep neural networks. To validate the applicability of the proposed explanation method, the real-life process log data delivered by the Volvo IT Belgium’s incident management system are used. The adopted deep learningDeep learning classifier achieves a good performance with the area under the ROC Curve of 0.94. The generated local explanations are also visualized and presented with relevant evaluation measures which are expected to increase the users’ trust in the black-box model.},
author = {Mehdiyev, Nijat and Fettke, Peter},
address = {Switzerland},
booktitle = {Interpretable Artificial Intelligence: A Perspective of Granular Computing},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2021},
isbn = {9783030649487},
issn = {1860-949X},
keywords = {Granular computing ; Process mining},
language = {eng},
pages = {1-28},
publisher = {Springer International Publishing AG},
series = {Studies in Computational Intelligence},
title = {Explainable Artificial Intelligence for Process Mining: A General Overview and Application of a Novel Local Explanation Approach for Predictive Process Monitoring},
volume = {937},
year = {2021},
}

@inproceedings{ZayakinViktor2022ESGa,
abstract = {The article presents an approach to the analyzing processes in different domains using data from various Internet sources (open databases, news feeds, social networks, etc.). This one is suitable to carry out cross-disciplinary research encompassing processes in various fields (for example, economics, medicine, politics, ecology, etc.) in which events can have mutual affects. The concept of event series is given as the main one in this study. Event series are defined via analogy with time series as a collection of values of some parameters of the investigated processes, where the type of event is indicated instead of the measurement time. The event series analysis should take into account not only the relationship of measurements with time (or the events chronology), but also the causal relationships that can be identified at the study of processes. The event series formation is based on using multifaceted ontology describing different aspects of research such as data sources and structure of information extracted from them to solve user's tasks, as well as domains and events, rules that characterize events, and the methods to solve tasks. The ontology is used when working with unstructured data to build an event log, which is formed in the first step when constructing event series. Next, the ontology is used to pre-process data before performing process mining tools applied to creating and analyzing models of processes. Using multifaceted ontology experts can define new rules for pre-processing data and generating event logs based on the concept of event-time series. These tools allow to generate more informative models.},
author = {Zayakin, Viktor and Lyadova, Lyudmila and Smirnov, Mikhail and Lanin, Viacheslav and Matta, Nada and Zamyatina, Elena},
booktitle = {2022 IEEE 16th International Conference on Application of Information and Communication Technologies (AICT)},
isbn = {1665451629},
issn = {2472-8586},
keywords = {Data Analysis ; Information retrieval ; Process mining ; Time measurements},
language = {eng},
pages = {1-6},
publisher = {IEEE},
title = {Event Series Generation and Analysis Based on Multifaceted Ontology},
year = {2022},
}

@article{DeneckèreRebecca2014IPMD,
abstract = {Understanding people's goals is a challenging issue that is met in many different areas such as security, sales, information retrieval, etc. Intention Mining aims at uncovering intentions from observations of actual activities. While most Intention Mining techniques proposed so far focus on mining individual intentions to analyze web engine queries, this paper proposes a generic technique to mine intentions from activity traces. The proposed technique relies on supervised learning and generates intentional models specified with the Map formalism. The originality of the contribution lies in the demonstration that it is actually possible to reverse engineer the underlying intentional plans built by people when in action, and specify them in models e.g. with intentions at different levels, dependencies, links with other concepts, etc. After an introduction on intention mining, the paper presents the Supervised Map Miner Method and reports two controlled experiments that were undertaken to evaluate precision, recall and F-Score. The results are promising since the authors were able to find the intentions underlying the activities as well as the corresponding map process model with satisfying accuracy, efficiency and performance.},
author = {Deneckère, Rebecca and Hug, Charlotte and Khodabandelou, Ghazaleh and Salinesi, Camille},
address = {Hershey},
copyright = {Copyright 2021 Elsevier B.V., All rights reserved.},
issn = {1947-8186},
journal = {International journal of information system modeling and design},
keywords = {Computer science ; Computer software ; Data mining ; Engineering design ; Information organization ; Information retrieval ; Information storage and retrieval systems ; Learning ; Mineral industries ; Miners ; Questions and answers ; Software engineering},
language = {eng},
number = {4},
pages = {22-47},
publisher = {IGI Global},
title = {Intentional Process Mining: Discovering and Modeling the Goals Behind Processes using Supervised Learning},
volume = {5},
year = {2014},
}

@incollection{PourbafraniMahsa2023ATfB,
abstract = {Recorded event data of processes inside organizations is a valuable source for providing insights and information using process mining. Most techniques analyze process executions at detailed levels, e.g., process instances, which may result in missing insights. Techniques at detailed levels using detailed event data should be complemented by techniques at aggregated levels. We designed and developed a standalone tool for diagnostics in event data of business processes based on both detailed and aggregated data and techniques. The data-driven framework first analyzes the event data of processes for possible compliance and performance problems, e.g., bottlenecks in processes. The results are used for aggregating the event data per window of time, i.e., extracting features in the time series format. The tool is able to uncover hidden insights in an explainable manner using time series analysis. The focus of the tool is to provide a data-driven business process analysis at different levels while reducing the dependencies on the user’s domain knowledge for interpretation and feature engineering steps. The tool is applied to both real-world and synthetic event data.},
author = {Pourbafrani, Mahsa and Gharbi, Firas and van der Aalst, Wil M. P. and Ortiz, Guadalupe and Troya, Javier and Ruiz-Cortés, Antonio and Delgado, Andrea and Segura, Sergio and Fernández, Pablo and Mirandola, Raffaela and Pautasso, Cesare and Navarro, Elena and Zirpins, Christian and Troya, Javier and Ortiz, Guadalupe and Mirandola, Raffaela and Pautasso, Cesare and Segura, Sergio and Zirpins, Christian and Delgado, Andrea and Navarro, Elena and Ruiz-Cortés, Antonio and Fernández, Pablo},
address = {Switzerland},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {9783031265068},
issn = {0302-9743},
keywords = {Process mining ; Time Factors},
language = {eng},
pages = {350-354},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {A Tool for Business Processes Diagnostics},
volume = {13821},
year = {2023},
}

@article{KrausAlexander2024Daob,
abstract = {Process resilience represents a core competence for organizations in light of an increasing number of process disruptions, such as sudden increases in case arrivals or absences in the workforce. It reflects an organization’s ability to restore a process to its acceptable performance level after a disruption. In this regard, the first key step for organizations towards achieving resilience is to understand how resilient their processes actually are. Although recognized as important, few works focus on such resilience assessment in a data-driven manner, thus barring organizations from gaining the necessary insights into how much their processes are affected by disruptions and how long it takes them to recover. To address this problem, we propose an approach for automated resilience assessment, based on recorded event data. Our approach interprets relevant process characteristics, such as the average lead time or arrival rate, as time series, which capture the development of the process execution over time. Based on these time series, it uses statistical modeling, specifically a vector autoregressive model, to determine the inter-relations between those characteristics and assess how the process performance responds to a disruption, i.e., a significant and temporal change in one of the process characteristics. We validate our approach by comparing its accuracy with a what-if analysis using a simulation model and demonstrate its effectiveness by assessing the resilience of the same process to diverse disruptions across different organizations.},
author = {Kraus, Alexander and Rehse, Jana-Rebecca and van der Aa, Han},
address = {Cham},
copyright = {The Author(s) 2024},
issn = {2948-2178},
journal = {Process Science},
keywords = {Research},
language = {eng},
number = {1},
publisher = {Springer International Publishing},
title = {Data-driven assessment of business process resilience},
volume = {1},
year = {2024},
}

@article{MebrahtuTeumzghiF2023Tioc,
abstract = {Abstract
In the last 6 years, hospitals in developed countries have been trialling the use of command centres for improving organizational efficiency and patient care. However, the impact of these command centres has not been systematically studied in the past. It is a retrospective population-based study. Participants were patients who visited the Bradford Royal Infirmary hospital, Accident and Emergency (A&E) Department, between 1 January 2018 and 31 August 2021. Outcomes were patient flow (measured as A&E waiting time, length of stay, and clinician seen time) and data quality (measured by the proportion of missing treatment and assessment dates and valid transition between A&E care stages). Interrupted time-series segmented regression and process mining were used for analysis. A&E transition time from patient arrival to assessment by a clinician marginally improved during the intervention period; there was a decrease of 0.9min [95% confidence interval (CI): 0.35–1.4], 3min (95% CI: 2.4–3.5), 9.7min (95% CI: 8.4–11.0), and 3.1min (95% CI: 2.7–3.5) during ‘patient flow program’, ‘command centre display roll-in’, ‘command centre activation’, and ‘hospital wide training program’, respectively. However, the transition time from patient treatment until the conclusion of consultation showed an increase of 11.5 min (95% CI: 9.2–13.9), 12.3min (95% CI: 8.7–15.9), 53.4min (95% CI: 48.1–58.7), and 50.2min (95% CI: 47.5–52.9) for the respective four post-intervention periods. Furthermore, the length of stay was not significantly impacted; the change was −8.8 h (95% CI: −17.6 to 0.08), −8.9 h (95% CI: −18.6 to 0.65), −1.67h (95% CI: −10.3 to 6.9), and −0.54 h (95% CI: −13.9 to 12.8) during the four respective post-intervention periods. It was a similar pattern for the waiting and clinician seen times. Data quality as measured by the proportion of missing dates of records was generally poor (treatment date = 42.7% and clinician seen date = 23.4%) and did not significantly improve during the intervention periods. The findings of the study suggest that a command centre package that includes process change and software technology does not appear to have a consistent positive impact on patient safety and data quality based on the indicators and data we used. Therefore, hospitals considering introducing a command centre should not assume there will be benefits in patient flow and data quality.},
author = {Mebrahtu, Teumzghi F and McInerney, Ciaran D and Benn, Jonathan and McCrorie, Carolyn and Granger, Josh and Lawton, Tom and Sheikh, Naeem and Habli, Ibrahim and Randell, Rebecca and Johnson, Owen},
address = {UK},
copyright = {The Author(s) 2023. Published by Oxford University Press on behalf of International Society for Quality in Health Care. 2023},
issn = {1353-4505},
journal = {International journal for quality in health care},
keywords = {Data Accuracy ; Hospitals ; Human beings ; National health services ; Retrospective Studies ; United Kingdom},
language = {eng},
number = {4},
publisher = {Oxford University Press},
title = {The impact of hospital command centre on patient flow and data quality: findings from the UK National Health Service},
volume = {35},
year = {2023},
}

@article{CuzzocreaAlfredo2019Pmot,
abstract = {Monitoring the performances of a business process is a key issue in many organizations, especially when the process must comply with predefined performance constraints. In such a case, empowering the monitoring system with prediction capabilities would allow us to know in advance a constraint violation, and possibly trigger corrective measures to eventually prevent the violation. Despite the problem of making run-time predictions for a process, based on pre-mortem log data, is an active research topic in Process Mining, current predictive monitoring approaches in this field only support predictions at the level of a single process instance, whereas process performance constraints are often defined in an aggregated form, according to predefined time windows. Moreover, most of these approaches cannot work well on the traces of a lowly-structured business process when these traces do not refer to well-defined process tasks/activities. For such a challenging setting, we define an approach to the problem of predicting whether the process instances of a given (unfinished) time window will violate an aggregate performance requirement. The approach mainly rely on inducing and integrating two complementary predictive models: (1) a clustering-based predictor for estimating the outcome of each ongoing process instance, (2) a time-series predictor for estimating the performance outcome of “future” process instances that will fall in the window after the moment when the prediction is being made (i.e. instances, not started yet, that will start by the end of the window). Both models are expected to benefit from the availability of aggregate context data regarding the environment that surrounds the process. This discovery approach is conceived as the core of an advanced performance monitoring system, for which an event-based conceptual architecture is here proposed. Tests on real-life event data confirmed the validity of our approach, in terms of accuracy, robustness, scalability, and usability.
•We focus on the context of complex event-based information system monitoring.•We provide a framework for supporting predictive monitoring of process performance indicators.•We face the problem of predicting whether (the process instances in) each current time window will violate an aggregate performance constraint, at different checkpoints inside the window.•Our prediction task is accomplished by inducing two kinds of models, which both take advantage of aggregate information on the state of the environment where the process is being executed: (1) a clustering-based model for estimating the outcome of each unfinished process instance, (2) ad-hoc time-series models for estimating global statistics on the outcome of future process instances that are expected to start by the end of the window.•We propose an event-based architecture for an innovative kind of monitoring infrastructure that integrates the proposed prediction approach.•We provide tests on real-life event data that confirmed the validity of the approach, in terms of both prediction accuracy and scalability.},
author = {Cuzzocrea, Alfredo and Folino, Francesco and Guarascio, Massimo and Pontieri, Luigi},
address = {OXFORD},
copyright = {2018 Elsevier Ltd},
issn = {0306-4379},
journal = {Information systems (Oxford)},
keywords = {Business ; Cluster analysis ; Computer science ; Information storage and retrieval systems ; Mathematical models ; Monitoring ; Technology},
language = {eng},
pages = {236-266},
publisher = {Elsevier Ltd},
title = {Predictive monitoring of temporally-aggregated performance indicators of business processes against low-level streaming events},
volume = {81},
year = {2019},
}

@incollection{MartjushevJ.2015CPDa,
abstract = {In recent years process mining techniques have matured. Provided that the process is stable and enough example traces have been recorded in the event log, it is possible to discover a high-quality process model that can be used for performance analysis, compliance checking, and prediction. Unfortunately, most processes are not in steady-state and process discovery techniques have problems uncovering “second-order dynamics” (i.e., the process itself changes while being analyzed). This paper describes an approach to discover a variety of concept drifts in processes. Unlike earlier approaches, we can discover gradual drifts and multi-order dynamics (e.g., recurring seasonal effects mixed with the effects of an economic crisis). We use a novel adaptive windowing approach to robustly localize changes (gradual or sudden). Our extensive evaluation (based on objective criteria) shows that the new approach is able to efficiently uncover a broad range of drifts in processes.},
author = {Martjushev, J. and Bose, R. P. Jagadeesh Chandra and van der Aalst, Wil M. P.},
address = {Cham},
booktitle = {Lecture Notes in Business Information Processing},
copyright = {Springer International Publishing Switzerland 2015},
isbn = {3319219146},
issn = {1865-1348},
keywords = {Change-point problems},
language = {eng},
pages = {161-178},
publisher = {Springer International Publishing},
series = {Lecture Notes in Business Information Processing},
title = {Change Point Detection and Dealing with Gradual and Multi-order Dynamics in Process Mining},
volume = {229},
year = {2015},
}

@inproceedings{ProkofyevaElizavetaS.2020DATP,
abstract = {Healthcare services are tightly connected with complex data analysis techniques to enable optimal resource allocation in medical institutions. This paper proposes a detailed analysis of incoming patient flow to local polyclinic by integrating clustering techniques, process mining and a concept of self-organizing systems. The study takes into account concepts based on models of managing social networks, the participants of which today can be both people and intelligent software. How could patient flow model be developed using a clinical pathways approach that combines clinical pathways tool, social media analysis, hierarchical agglomerative clustering method and probabilistic topic modeling to investigate the optimal resource utilization of medical facility? The methodology to answer this research question was demonstrated using a time- series clustering (kmedoids, Ward's method, Latent Dirichlet Allocation, Additive Regularization of Topic Models), Naive Bayes classifier based on public real data of 64668 depersonalized patient- doctor of 32 specialties conversions. In this paper, a modeling methodology for heterogeneous patient flow segmentation is proposed. The presented approaches serve as the foundation for the further development of a queuing system model of a medical institution. In addition, the shared economy principles are applied by the development of such service that would reduce the workload of appointments to therapists by matching patients to needed doctors.},
author = {Prokofyeva, Elizaveta S. and Maltseva, Svetlana V. and Fomichev, Nikita Y. and Kudryashov, Alexey G.},
booktitle = {2020 IEEE 22nd Conference on Business Informatics (CBI)},
isbn = {9781728199269},
issn = {2378-1971},
keywords = {Business ; Critical Pathways ; Data Analysis ; Economics ; Planning ; Social networks},
language = {eng},
pages = {71-77},
publisher = {IEEE},
title = {Data-Driven Approach To Patient Flow Management And Resource Utilization In Urban Medical Facilities},
volume = {2},
year = {2020},
}

@inproceedings{NakayamaYoshihito2018TPDA,
abstract = {In the decision-making of sales activities, the means for greatly increasing the efficiency of sales activities are required by eliminating individuals' factors such as experience and intuition. For this purpose, we are developing a business decision support system using a machine learning model. To establish a process discovery method that extracts regularity from the decision-making, it is necessary to learn the process of sales activities with high order acceptance probability. In this paper, we introduce novel two preprocessing techniques of process mining: an activity estimation based on unstructured data such as daily business reports and a process estimation for stochastically expressing the regularity in an atypical process, and finally find out effective learning algorithms. Especially in process estimation, comparison of plural algorithms reveals the superiority of Hidden Markov Model. Though Hidden Markov Model has an issue to need a large amount of daily business report data including time series, by automatically generating activity data between salespersons and customers with a simulator, it is realized to increase the number of training data. As a result, it is confirmed that the new process discovery method presented in this paper is effective for discovering atypical decision-making process.},
author = {Nakayama, Yoshihito and Mori, Masahiro and Naruse, Yoshiaki and Morikawa, Hiroyuki},
booktitle = {2018 Joint 10th International Conference on Soft Computing and Intelligent Systems (SCIS) and 19th International Symposium on Advanced Intelligent Systems (ISIS)},
isbn = {9781538626337},
keywords = {Decision making ; Process mining},
language = {eng},
pages = {1394-1399},
publisher = {IEEE},
title = {The Process Discovery Approaches for Decision Making in Sales Activities},
year = {2018},
}

@inproceedings{cdi_unpaywall_primary_10_5220_0011035000003179,
language = {eng},
title = {Process Diagnostics at Coarse-grained Levels},
}

@incollection{ImpedovoAngelo2020SPDD,
abstract = {Traditional process mining approaches learn process models assuming that processes are in steady-state. This does not comply with the flexibility and adaptation often requested for information systems and business models. In fact, these approaches should discover variations to adapt to new circumstances, which is a peculiarity that conventional change analysis based on time-series, could not provide, because the processes are complex artifacts. This problem can be handled with change-aware structured representations, such as those typically used for network data. In this paper, we propose a novel pattern-based change detection (PBCD) algorithm for discovering and characterizing changes in event logs encoded as dynamic networks. In particular, PBCDs are unsupervised change detection methods, based on observed changes in sets of patterns observed over time, which are able to simultaneously detect and characterize changes in evolving data. Experimental results, on both real and synthetic data, show the usefulness and the increased accuracy with respect to state-of-the-art solutions.},
author = {Impedovo, Angelo and Mignone, Paolo and Loglisci, Corrado and Ceci, Michelangelo},
address = {Cham},
booktitle = {Discovery Science},
copyright = {Springer Nature Switzerland AG 2020},
isbn = {9783030615260},
issn = {0302-9743},
language = {eng},
pages = {451-467},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {Simultaneous Process Drift Detection and Characterization with Pattern-Based Change Detectors},
volume = {12323},
year = {2020},
}

@inproceedings{alma9994232876401488,
author = {Bertrand, Yannis and De Weerdt, Jochen and Serral Asensio, Estefanía},
isbn = {978-3-031-41620-0},
issn = {0302-9743},
keywords = {Social Sciences ; Science & Technology ; Technology ; Business ; Computer Science Artificial Intelligence ; Computer Science Interdisciplinary Applications ; Management ; Operations Research & Management Science ; Business & Economics ; Computer Science ; Process mining ; Internet of Things ; Trace clustering ; IoT-enhanced process mining ; BUSINESS PROCESS ; G0B6922N#56765431},
language = {eng},
organization = {Burattin, A (Editor)},
publisher = {Springer; Cham},
title = {A Novel Multi-Perspective Trace Clustering Technique for IoT-enhanced Processes: A Case Study in Smart Manufacturing},
year = {2023},
}

@incollection{LaenderAlbertoH.F2019CPDD,
abstract = {Recent research has introduced ideas from concept drift into process mining to enable the analysis of changes in business processes over time. This stream of research, however, has not yet addressed the challenges of drift categorization, drilling-down, and quantification. In this paper, we propose a novel technique for managing process drifts, called Visual Drift Detection (VDD), which fulfills these requirements. The technique starts by clustering declarative process constraints discovered from recorded logs of executed business processes based on their similarity and then applies change point detection on the identified clusters to detect drifts. VDD complements these features with detailed visualizations and explanations of drifts. Our evaluation, both on synthetic and real-world logs, demonstrates all the aforementioned capabilities of the technique.},
author = {Laender, Alberto H. F and Pernici, Barbara and Lim, Ee-Peng and de Oliveira, José Palazzo M},
address = {Switzerland},
booktitle = {Conceptual Modeling},
copyright = {Springer Nature Switzerland AG 2019},
isbn = {9783030332228},
issn = {0302-9743},
keywords = {Declarative process models ; Process drifts ; Process mining},
language = {eng},
pages = {119-135},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Comprehensive Process Drift Detection with Visual Analytics},
volume = {11788},
year = {2019},
}

@article{MeiraNetoAntonioCarlos2024RtTM,
abstract = {Coping with concept drifts in process mining remains highly pertinent, given the inherently dynamic essence of real-world business processes. Daily operations see processes undergoing continuous changes due to changing market demands, technological advances, or organizational restructuring. Conceptual drifts may emerge unexpectedly at any time, impacting process behavior significantly. Neglecting to manage these drifts can lead to obsolete process models, inaccurate performance analyses, and misguided decision-making. Researchers have been struggling to address several issues related to concept drifts in process mining; nevertheless, this question persists open. As a contribution, we previously proposed an approach based on transformed transition matrices as an efficient, simple, and extensible data structure, first applied to the task of detecting concept drifts. For this purpose, three strategies were adjusted to function with transformed transition matrices. We evaluated the approach’s effectiveness by initially using one set of event logs, contrasting its performance against cutting-edge benchmark methods in experimental settings. In this paper, we revisit the proposed approach, by expanding and reinforcing its evaluation through an additional set of event logs. The findings underscore the transformed transition matrix’s capability to encapsulate manifold features drawn from event logs, particularly those tied to process drifts via windowed comparisons. We show how these extracted features contribute to pinpointing sudden process drifts in control flow, specifically in an offline scenario. The experimental outcomes hold promise, signifying the potential of the three adapted detection strategies.},
author = {Meira Neto, Antonio Carlos and de Sousa, Rafael Gaspar and Fantinato, Marcelo and Peres, Sarajane Marques},
address = {Singapore},
copyright = {The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd 2024. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.},
issn = {2662-995X},
journal = {SN computer science},
keywords = {Computer science ; Decision making ; Drift ; Process mining ; Vision},
language = {eng},
number = {1},
pages = {188-},
publisher = {Springer Nature Singapore},
title = {Revisiting the Transition Matrix-Based Concept Drift Approach: Improving the Detection Task Reliability Through Additional Experimentation},
volume = {5},
year = {2024},
}

@article{PishgarM.2022Pou3,
abstract = {Background Intensive Care Unit (ICU) readmissions in patients with heart failure (HF) result in a significant risk of death and financial burden for patients and healthcare systems. Prediction of at-risk patients for readmission allows for targeted interventions that reduce morbidity and mortality. Methods and results We presented a process mining/deep learning approach for the prediction of unplanned 30-day readmission of ICU patients with HF. A patient's health records can be understood as a sequence of observations called event logs; used to discover a process model. Time information was extracted using the DREAM (Decay Replay Mining) algorithm. Demographic information and severity scores upon admission were then combined with the time information and fed to a neural network (NN) model to further enhance the prediction efficiency. Additionally, several machine learning (ML) algorithms were developed to be used as the baseline models for the comparison of the results. Results By using the Medical Information Mart for Intensive Care III (MIMIC-III) dataset of 3411 ICU patients with HF, our proposed model yielded an area under the receiver operating characteristics (AUROC) of 0.930, 95% confidence interval of [0.898-0.960], the precision of 0.886, sensitivity of 0.805, accuracy of 0.841, and F-score of 0.800 which were far better than the results of the best baseline model and the existing literature. Conclusions The proposed approach was capable of modeling the time-related variables and incorporating the medical history of patients from prior hospital visits for prediction. Thus, our approach significantly improved the outcome prediction compared to that of other ML-based models and health calculators.},
author = {Pishgar, M. and Theis, J. and Del Rios, M. and Ardati, A. and Anahideh, H. and Darabi, H.},
address = {LONDON},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
issn = {1472-6947},
journal = {BMC medical informatics and decision making},
keywords = {Algorithms ; Artificial intelligence ; Calculators ; Comorbidity ; Confidence intervals ; Congestive heart failure ; Diseases ; Electronic Health Records ; Heart failure ; Hospital care ; Hospitals ; Human beings ; Intensive care units ; Machine learning ; Medicaid ; Medical informatics ; Medicare ; Mortality ; Patient Readmission ; Patients ; Process mining ; Prophecies ; Research ; Statistics},
language = {eng},
number = {1},
pages = {117-117},
publisher = {Springer Nature},
title = {Prediction of unplanned 30-day readmission for ICU patients with heart failure},
volume = {22},
year = {2022},
}

@article{KanDaoyu2024Elad,
abstract = {Anomaly detection is widely used in the field of business process management, and researchers have proposed various anomaly detection algorithms to detect anomalies in event logs. However, existing research focuses on detecting anomalies in event logs at the data level, ignoring the problem of anomalies caused by event log control flow, especially behavioral relationships, and identifying behavioral anomalies as normal, leading to an increase in the false-negative rate of anomaly detection results, which negatively affects the performance of process mining. To solve the above problems, this article proposes an auto-encoder-based anomaly detection approach to achieve the detection of behavioral relationship anomalies in event logs through the reconstruction error between images. The approach first considers event logs containing behavioral relationships, converts the logs into images as input to the auto-encoder, and analyses the reconstruction error between images to propose a reconstruction error threshold for anomaly detection. The algorithm is able to achieve anomaly detection of behavioral relationships in event logs and reduce the false-negative rate of anomaly detection results. Experiments on synthetic datasets and real datasets show that the proposed approach can improve the recall rate and F1-score of event log anomaly detection effectively.},
author = {Kan, Daoyu and Fang, Xianwen},
address = {Berlin/Heidelberg},
copyright = {The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.},
issn = {0942-4962},
journal = {Multimedia systems},
keywords = {Algorithms ; Computer graphics ; Computer networks ; Computer science ; Cryptography ; Image processing ; Image reconstruction ; Multimedia systems ; Technology},
language = {eng},
number = {1},
publisher = {Springer Berlin Heidelberg},
title = {Event log anomaly detection method based on auto-encoder and control flow},
volume = {30},
year = {2024},
}

@article{BelhadiAsma2022Hiff,
abstract = {This paper investigates the automated medical learning and proposes hybrid intelligent framework, called Hybrid Automated Medical Learning (HAML). The goal is the efficient combination of several intelligent components in order to automatically learn the medical data. Multi agents system is proposed by using distributed deep learning, and knowledge graph for learning medical data. The distributed deep learning is used for efficient learning of the different agents in the system, where the knowledge graph is used for dealing with heterogeneous medical data. To demonstrate the usefulness and accuracy of the HAML framework, intensive simulations on medical data were conducted. A wide range of experiments were conducted to verify the efficiency of the proposed system. Three case studies are discussed in this research, the first case study is related to process mining, and more precisely on the ability of HAML to detect relevant patterns from event medical data. The second case study is related to smart building, and the ability of HAML to recognize the different activities of the patients. The third one is related to medical image retrieval, and the ability of HAML to find the most relevant medical images according to the image query. The results show that the developed HAML achieves good performance compared to the most up‐to‐date medical learning models regarding both the computational and cost the quality of returned solutions.},
author = {Belhadi, Asma and Djenouri, Youcef and Diaz, Vicente Garcia and Houssein, Essam H. and Lin, Jerry Chun‐Wei},
address = {HOBOKEN},
copyright = {2021 The Authors. published by John Wiley & Sons Ltd.},
issn = {0266-4720},
journal = {Expert systems},
keywords = {Automation ; Case studies ; Computer science ; Diagnostic imaging ; Hybrid systems ; Multiagent systems ; Technology},
language = {eng},
number = {6},
publisher = {Wiley},
title = {Hybrid intelligent framework for automated medical learning},
volume = {39},
year = {2022},
}

@article{Rama-ManeiroEfrén2024Ergn,
abstract = {Predictive monitoring is a subfield of process mining that aims to predict how a running case will unfold in the future. One of its main challenges is forecasting the sequence of activities that will occur from a given point in time —suffix prediction—. Most approaches to the suffix prediction problem learn to predict the suffix by learning how to predict the next activity only, while also disregarding structural information present in the process model. This paper proposes a novel architecture based on an encoder-decoder model with an attention mechanism that decouples the representation learning of the prefixes from the inference phase, predicting only the activities of the suffix. During the inference phase, this architecture is extended with a heuristic search algorithm that selects the most probable suffix according to both the structural information extracted from the process model and the information extracted from the log. Our approach has been tested using 12 public event logs against 6 different state-of-the-art proposals, showing that it significantly outperforms these proposals.},
author = {Rama-Maneiro, Efrén and Vidal, Juan C. and Lama, Manuel and Monteagudo-Lago, Pablo},
address = {Vienna},
copyright = {The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2024. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.},
issn = {0010-485X},
journal = {Computing},
keywords = {Artificial intelligence ; Computer networks ; Computer science ; Computer software ; Inference ; Machine learning ; Monitoring ; Predictive analytics ; Prophecies ; Software engineering ; Technology},
language = {eng},
number = {9},
pages = {3085-3111},
publisher = {Springer Vienna},
title = {Exploiting recurrent graph neural networks for suffix prediction in predictive monitoring},
volume = {106},
year = {2024},
}

@article{KołakowskaAgata2022AoFI,
abstract = {Tourism is a significant branch of many world economies. Many factors influence the volume of tourist traffic and the prices of trips. There are factors that clearly affect tourism, such as COVID-19. The paper describes the methods of machine learning and process mining that allow for assessing the impact of various factors (micro, mezzo and macro) on the prices of tourist offers. The methods were used on large sets of real data from two tour operators, and the results of these studies are discussed in this paper. The research presented is part of a larger project aiming at predicting trip prices. It answers the question of which factors have the greatest impact on the price and which can be omitted in further work. Nevertheless, the dynamic world situation suggests that the ranking of factors may change and the presented universal methods may provide different results in the coming years.},
author = {Kołakowska, Agata and Godlewska, Magdalena},
address = {BASEL},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
issn = {2076-3417},
journal = {Applied sciences},
keywords = {Algorithms ; Chemistry ; Commission merchants ; COVID-19 Pandemic 2020- ; Economic indicators ; Engineering ; Foreign exchange rates ; Gross domestic product ; Machine learning ; Manufacturers' agents ; Materials science ; Pandemics ; Physical sciences ; Physics ; Prices ; Process mining ; Technology ; Tourism ; Tourists ; Travel},
language = {eng},
number = {24},
pages = {12938-},
publisher = {Mdpi},
title = {Analysis of Factors Influencing the Prices of Tourist Offers},
volume = {12},
year = {2022},
}

@article{TaxNiek2017MPMD,
abstract = {Studies in Computational Intelligence, 751 (2017) 83-104 Process mining techniques focus on extracting insight in processes from event
logs. Process mining has the potential to provide valuable insights in
(un)healthy habits and to contribute to ambient assisted living solutions when
applied on data from smart home environments. However, events recorded in smart
home environments are on the level of sensor triggers, at which process
discovery algorithms produce overgeneralizing process models that allow for too
much behavior and that are difficult to interpret for human experts. We show
that abstracting the events to a higher-level interpretation can enable
discovery of more precise and more comprehensible models. We present a
framework for the extraction of features that can be used for abstraction with
supervised learning methods that is based on the XES IEEE standard for event
logs. This framework can automatically abstract sensor-level events to their
interpretation at the human activity level, after training it on training data
for which both the sensor and human activity events are known. We demonstrate
our abstraction framework on three real-life smart home event logs and show
that the process models that can be discovered after abstraction are more
precise indeed.},
author = {Tax, Niek and Sidorova, Natalia and Haakma, Reinder and van der Aalst, Wil M. P},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
title = {Mining Process Model Descriptions of Daily Life through Event Abstraction},
year = {2017},
}

@incollection{KimInkyu2022PPSA,
abstract = {Using data from the audit trail of an electronic medical record system, we examine the effects of a disruption on the clinical documentation process. We use process mining to construct a network that describes the process and then we use a latent factor selection model to analyze changes to that network. Rather than attempting to discover a particular process model, our goal is to identify theory-based factors that explain change and stability in the overall pattern of actions. We conduct the analysis at two levels of granularity and we compare time periods with and without disruption. The paper contributes to current research on routine dynamics as network dynamics by demonstrating the use of network science to predict the structure of an organizational routine.},
author = {Kim, Inkyu and Frank, Kenneth A. and Wolf, Julie Ryan and Pentland, Brian T. and Weber, Barbara and Marrella, Andrea and Weber, Barbara and Marrella, Andrea},
address = {Switzerland},
booktitle = {Business Process Management Workshops},
copyright = {Springer Nature Switzerland AG 2022},
isbn = {9783030943424},
issn = {1865-1348},
language = {eng},
pages = {221-231},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Predicting Process Structure After a Disruption: An Example from the Clinical Documentation Process},
volume = {436},
year = {2022},
}

@article{SzpyrkaMarcin2020Ccoa,
abstract = {Conformance checking is a process mining technique that compares a process model with an event log of the same process to check whether the current execution stored in the log conforms to the model and vice versa. This paper deals with the conformance checking of a longwall shearer process. The approach uses place-transition Petri nets with inhibitor arcs for modeling purposes. We use event log files collected from a few coal mines located in Poland by Famur S.A., one of the global suppliers of coal mining machines. One of the main advantages of the approach is the possibility for both offline and online analysis of the log data. The paper presents a detailed description of the longwall process, an original formal model we developed, selected elements of the approach's implementation and the results of experiments.},
author = {Szpyrka, Marcin and Brzychczy, Edyta and Napieraj, Aneta and Korski, Jacek and Nalepa, Grzegorz J.},
address = {BASEL},
copyright = {Copyright 2021 Elsevier B.V., All rights reserved.},
issn = {1996-1073},
journal = {Energies},
keywords = {Coal mines and mining ; Internet of things ; Mining machinery ; Petri nets ; Technology},
language = {eng},
number = {24},
pages = {6630-},
publisher = {Mdpi},
title = {Conformance checking of a longwall shearer operation based on low-level events},
volume = {13},
year = {2020},
}

@incollection{WuytsBrecht2023DPtD,
abstract = {Modern business processes are often characterized by continuous change, which can lead to bias in the results of process mining techniques that assume a static process. This bias is caused by concept drift, which can manifest in many forms and affect various process perspectives. Current research on concept drift in process mining has focused on drift detection techniques in the control-flow perspective, with limited capabilities for comprehensive dynamic profiling of event logs. To address this gap, this paper presents the DyLoPro framework, a generic approach that facilitates the exploration of event log dynamics over time using visual analytics. The framework caters to all types of event logs and allows for the exploration of event log dynamics from various process perspectives, both individually and combined with the performance perspective. Additionally, the framework is accompanied by an efficient and user-friendly Python library, rendering it a valuable instrument for both researchers and practitioners. A case study using large real-life event logs demonstrates the effectiveness of the framework.},
author = {Wuyts, Brecht and Weytjens, Hans and vanden Broucke, Seppe and De Weerdt, Jochen and Sadiq, Shazia and Janiesch, Christian and Di Francescomarino, Chiara and Burattin, Andrea},
address = {Switzerland},
booktitle = {Business Process Management},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {9783031416194},
issn = {0302-9743},
keywords = {Process mining ; Visual analytics},
language = {eng},
pages = {146-162},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {DyLoPro: Profiling the Dynamics of Event Logs},
volume = {14159},
year = {2023},
}

@incollection{BurattinAndrea2018AFfO,
abstract = {Conformance checking – a branch of process mining – focuses on establishing to what extent actual executions of a process are in line with the expected behavior of a reference model. Current conformance checking techniques only allow for a-posteriori analysis: the amount of (non-)conformant behavior is quantified after the completion of the process instance. In this paper we propose a framework for online conformance checking: not only do we quantify (non-)conformant behavior as the execution is running, we also restrict the computation to constant time complexity per event analyzed, thus enabling the online analysis of a stream of events. The framework is instantiated with ideas coming from the theory of regions, and state similarity. An implementation is available in ProM and promising results have been obtained.},
author = {Burattin, Andrea and Carmona, Josep and Teniente, Ernest and Weidlich, Matthias and Teniente, Ernest and Weidlich, Matthias},
address = {Switzerland},
booktitle = {Business Process Management Workshops},
copyright = {Springer International Publishing AG 2018},
isbn = {9783319740294},
issn = {1865-1348},
keywords = {Business ; Data mining ; Data processing ; Management},
language = {eng},
pages = {165-177},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {A Framework for Online Conformance Checking},
volume = {308},
year = {2018},
}

@incollection{BurattinAndrea2015LCAB,
abstract = {Nowadays, organizational information systems are able to collect high volumes of data in event logs every day. Through process mining techniques, it is possible to extract information from such logs to support organizations in checking process conformance, detecting bottlenecks, and carrying on performance analysis. However, to analyze such “big data” through process mining, events coming from process executions (in the form of event streams) must be processed on-the-fly as they occur. The work presented in this paper is built on top of a technique for the online discovery of declarative process models presented in our previous work. In particular, we introduce a tool providing a dynamic visualization of the models discovered over time showing, as a “process movie”, the sequence of valid business rules at any point in time based on the information retrieved from an event stream. The effectiveness of the visualizer is validated through an event stream pertaining to health insurance claims handling in a travel agency.},
author = {Burattin, Andrea and Cimitile, Marta and Maggi, Fabrizio Maria and Mendling, Jan and Fournier, Fabiana},
address = {Cham},
booktitle = {Business Process Management Workshops},
copyright = {Springer International Publishing Switzerland 2015},
isbn = {9783319158945},
issn = {1865-1348},
language = {eng},
pages = {408-419},
publisher = {Springer International Publishing},
series = {Lecture Notes in Business Information Processing},
title = {Lights, Camera, Action! Business Process Movies for Online Process Discovery},
volume = {202},
year = {2015},
}

@article{RuschelEdson2017MSDf,
abstract = {Well-defined intervals between preventive maintenance inspections help increase the availability of process equipment. This work integrates probabilistic and predictive models constructed from event logs information, through process mining techniques, to estimate the variations of process cycle time. A function for equipment availability is defined and gradual changes in intervals between maintenance inspections are performed until the wasted time for this function is minimized and the best interval is found. Different scenarios can be analyzed simulating variations in probabilities of activities occurrence, providing better support in scheduling maintenance activities. Results show that losses can be reduced by optimizing the intervals between maintenance inspections.},
author = {Ruschel, Edson and Santos, Eduardo Alves Portela and Loures, Eduardo de Freitas Rocha},
copyright = {2017 The Authors},
issn = {2351-9789},
journal = {Procedia manufacturing},
keywords = {Process mining},
language = {eng},
pages = {1127-1134},
publisher = {Elsevier B.V},
title = {Mining Shop-Floor Data for Preventive Maintenance Management: Integrating Probabilistic and Predictive Models},
volume = {11},
year = {2017},
}

@inproceedings{WangXiaolei2022MMAD,
abstract = {Anomaly detection for discrete event logs can provide critical information for building secure and reliable systems in various application domains, such as large scale data centers, autonomous driving, and intrusion detection. However, the task is very challenging due to the lack of a clear understanding and definition of anomaly in the specific problem space, and the log data is often highly complex with temporal correlation. Existing deep learning based methods mostly suffer from such issues as overfitting, uncertainty or low interpretability; consequently, the detection results may be inaccurate, with little information to help security analysts diagnose the reported anomalies with high confidence. To tackle this challenge, in this research, we propose a general framework named MADDC, which aims to (1) accurately perform Multi-scale Anomaly Detection, Diagnosis and Correction for discrete event logs, and (2) help analysts further mitigate anomalies based on diagnosis results. Specifically, we first design a new anomaly critic for LSTM variational autoencoder based model to alleviate overfitting and reduce false negatives during anomaly detection. As one of our main contributions, we then introduce process mining technique to build process-centric workflow models in an unsupervised manner, which forms the ‘normal’ context of an event sequence and help perform accurate and consistent anomaly diagnosis through global sequence alignment. Experiments on publicly available datasets show that MADDC not only outperformed several representative methods in terms of detection accuracy, but also could improve the visibility to abnormal deviations from normal execution, hence helping security analysts understand anomalies and make further corrections.},
author = {Wang, Xiaolei and Yang, Lin and Li, Dongyang and Ma, Linru and He, Yongzhong and Xiao, Junchao and Liu, Jiyuan and Yang, Yuexiang},
address = {New York, NY, USA},
booktitle = {ACM International Conference Proceeding Series},
copyright = {2022 ACM},
isbn = {9781450397599},
language = {eng},
pages = {769-784},
publisher = {ACM},
title = {MADDC: Multi-Scale Anomaly Detection, Diagnosis and Correction for Discrete Event Logs},
year = {2022},
}

@inproceedings{YangSen2017ADPR,
abstract = {We present an approach for improving the performance of complex knowledge-based processes by providing data-driven step-by-step recommendations. Our framework uses the associations between similar historic process performances and contextual information to determine the prototypical way of enacting the process. We introduce a novel similarity metric for grouping traces into clusters that incorporates temporal information about activity performance and handles concurrent activities. Our data-driven recommender system selects the appropriate prototype performance of the process based on user-provided context attributes. Our approach for determining the prototypes discovers the commonly performed activities and their temporal relationships. We tested our system on data from three real-world medical processes and achieved recommendation accuracy up to an F1 score of 0.77 (compared to an F1 score of 0.37 using ZeroR) with 63.2% of recommended enactments being within the first five neighbors of the actual historic enactments in a set of 87 cases. Our framework works as an interactive visual analytic tool for process mining. This work shows the feasibility of data-driven decision support system for complex knowledge-based processes.},
author = {Yang, Sen and Dong, Xin and Sun, Leilei and Zhou, Yichen and Farneth, Richard A. and Xiong, Hui and Burd, Randall S. and Marsic, Ivan},
address = {New York, NY, USA},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
copyright = {2017 ACM},
isbn = {1450348874},
language = {eng},
pages = {2111-2120},
publisher = {ACM},
title = {A Data-driven Process Recommender Framework},
volume = {129685},
year = {2017},
}

@incollection{ZhouWenjun2024EDaP,
abstract = {Process mining studies ways to use event data generated by information systems to understand and improve the business processes of organizations. One of the core problems in process mining is process discovery. A process discovery algorithm takes event data as input and constructs a process model that describes the processes the system that generated the data can execute. The discovered model, hence, aims to represent both historical processes with traces in the data and the yet unseen processes of the system (total generalization). In this paper, we introduce process forecasting as an alternative approach to process discovery. First, given historical event data, the corresponding future event data is forecasted for a requested period in the future (event data forecasting). Then, a process model is constructed from the forecasted data to describe the processes the system is anticipated to execute during the target future period (process model forecasting). The benefits of this alternative approach are at least twofold. Firstly, it divides the problem into two fundamentally different sub-problems that can be studied and mastered separately. Secondly, a forecasted model that describes the processes of the system from a given period rather than in general (tailored generalization) can help organizations plan future operations and process improvement initiatives.},
author = {Zhou, Wenjun and Polyvyanyy, Artem and Bailey, James and Islam, Shareeful and Sturm, Arnon and Islam, Shareeful and Sturm, Arnon},
address = {Switzerland},
booktitle = {Intelligent Information Systems},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {3031609999},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {3-10},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {Event Data and Process Model Forecasting},
volume = {520},
year = {2024},
}

@incollection{BourichaHajer2023IASf,
abstract = {With the significant increase in information in the system log files, much research is based on the log files to improve the process. System logs contain a lot of information at different times about the behavior of the system and user. To enhance the process based on log files, the users’ behavior must be learned. With process discovery, an intentional process model and prediction strategies can be learned from log data. However, system logs do not fulfill the requirements that process discovery and prediction algorithms place on log files. To solve this problem, a new ensemble-based multi-intelligent agent system is introduced for discovering intentional process models and predicting users’ strategies in intention mining. This research proposal, therefore, proposes an architecture of four layers for intelligent agents to generate an intention mining process based on the communication coordination of intelligent agents, and we propose an HMM-LSTM-based hybrid solution to model and predict strategies of students using the case study of Educational Process Mining (EPM): A Learning Analytics Data Set.},
author = {Bouricha, Hajer and Hsairi, Lobna and Ghedira, Khaled},
address = {Switzerland},
booktitle = {Intelligent Systems Design and Applications},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {9783031355097},
issn = {2367-3370},
language = {eng},
pages = {234-243},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Intelligent Agents System for Intention Mining Using HMM-LSTM Model},
volume = {717},
year = {2023},
}

@incollection{VijayakamalM.2021AAtA,
abstract = {Enterprises whose businesses are driven by web-based or cloud-based applications contain thousands of business processes involved. Due to the dynamic runtime environments and distributed nature of business processes and dependencies, there is possibility of noise and anomalies. Moreover, naturally, businesses are interested in finding anomalies in business processes and rectify them for improving quality of service (QoS). Especially, as part of process mining, anomaly detection has become an important research area in the contemporary era. Many anomaly detection methods came into existence based on machine learning techniques. There are attempts made using autoencoders for business process anomaly detection. However, from the literature, it is understood that there is need for a deep learning-based autoencoder with unsupervised learning approach for efficient detection of anomalies by analysing business process event logs. Towards this end, in this paper, we proposed a methodology and defined an algorithm known as deep learning encoder-based anomaly detection (DLE-AD) for enhancing the ability of anomaly detection. From the experiments, it is revealed that deep learning-based anomaly detection showed better performance over the traditional approaches. The proposed algorithm is evaluated against state of the art and found that it outperforms the existing methods.},
author = {Vijayakamal, M. and Vasumathi, D.},
address = {Singapore},
booktitle = {Soft Computing and Signal Processing},
copyright = {The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022},
isbn = {981161248X},
issn = {2194-5357},
language = {eng},
pages = {363-374},
publisher = {Springer},
series = {Advances in Intelligent Systems and Computing},
title = {A Novel Approach to Detect Anomalies in Business Process Event Logs Using Deep Learning Algorithm},
volume = {1340},
year = {2021},
}

@inproceedings{ScheibelBeate2022ODMa,
abstract = {Decision mining enables discovery of decision rules guiding the control flow in processes. Existing decision mining techniques deal with different kinds of decision rules, e.g., overlapping rules, or including data elements, for example, time series data. Though online process mining and monitoring are gaining traction, online decision mining algorithms are still missing. Decision rules can be, similarly to process models, subject to change during runtime due to, for example, changing regulations or customer requirements. In order to address these runtime challenges, this paper proposes an approach that i) discovers decision rules during runtime and ii) continuously monitors and adapts discovered rules to reflect changes. Furthermore, the concept of a decision rule history is proposed, enabling (manual) identification of change patterns. The feasibility and the applicability of the approach is evaluated based on three synthetic datasets, BPIC12, BPIC20 and sepsis data set.},
author = {Scheibel, Beate and Rinderle-Ma, Stefanie},
address = {Cham},
booktitle = {Conceptual Modeling},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {9783031179945},
issn = {0302-9743},
language = {eng},
pages = {271-280},
publisher = {Springer International Publishing},
title = {Online Decision Mining and Monitoring in Process-Aware Information Systems},
volume = {13607},
year = {2022},
}

@incollection{PietersAnneloreJellemijn2022CPMa,
abstract = {This research investigates in how far AI methods can support the prediction of bed occupancy in hospital units based on individual patient data. We combine process mining and a Deep Spatial-Temporal Graph Modeling algorithm and show that this improves the performance of the prediction over existing approaches. To improve the model even more it is extended with knowledge available from patient records, like the day of the week, the time of the day, whether it is a vacation day or not and the amount of emergency cases per data point.},
author = {Pieters, Annelore Jellemijn and Schlobach, Stefan},
address = {Cham},
booktitle = {Health Information Science},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {3031206266},
issn = {0302-9743},
language = {eng},
pages = {76-87},
publisher = {Springer Nature Switzerland},
series = {Lecture Notes in Computer Science},
title = {Combining Process Mining and Time Series Forecasting to Predict Hospital Bed Occupancy},
volume = {13705},
year = {2022},
}

@article{BicknellJohnW.2021Dbsu,
abstract = {Detecting and elucidating botnets is an active area of research. Using explainable, highly scalable Apache Spark-based artificial intelligence, process mining technologies are presented which illuminate bot activity within terrorist Twitter data. A derived hidden Markov model suggests that bot logic uses information camouflage in order to disguise intentions similar to World War II Nazi propagandists and Soviet-era practitioners of information warfare enhanced with reflexive control. A future effort is presented which strings together best of breed techniques into a composite classification algorithm in order to improve continually the discovery of malicious accounts, understand cross-platform weaponized botnet dynamics, and model adversarial information warfare campaigns recursively.},
author = {Bicknell, John W. and Krebs, Werner G.},
address = {New York},
copyright = {Springer Science+Business Media, LLC, part of Springer Nature 2020},
issn = {1381-298X},
journal = {Computational and mathematical organization theory},
keywords = {Algorithms ; Artificial intelligence ; Camouflage ; Campaigns ; Classification ; Computer science ; Disguise ; Information warfare ; Management ; Markov processes ; Mathematics ; Misinformation ; Organizational sociology ; Physical sciences ; Process mining ; Signal processing ; Social media ; Social sciences ; Sociology ; Technology},
language = {eng},
number = {2},
pages = {161-178},
publisher = {Springer US},
title = {Detecting botnet signals using process mining},
volume = {27},
year = {2021},
}

@article{Fontenla-SecoYago2022Afft,
abstract = {[Display omitted]
•Healthcare processes are highly dynamic, complex, ad-hoc and multi-disciplinary.•Analysis results of health processes are complex to understand for health experts.•New ways of conveying process mining analysis results are needed.•Natural Language Descriptions help on understanding process analysis.•Clear preference of textual vs visual representations of data is shown.
In this paper, we propose a framework for the automatic generation of natural language descriptions of healthcare processes using quantitative and qualitative data and medical expert knowledge. Inspired by the demand of novel ways of conveying process mining analysis results of healthcare processes (Rojas et al., 2016), our framework is based on the most widely used Data-To-Text (D2T) pipeline (Reiter, 2007) and on the usage of process mining techniques. Backed by a general model that handles process data, this framework is able to quantify attributes in time during a process life-span, recall temporal relations and waiting times between events and its possible causes and compare case (patient) attributes between groups, among other features. Through integrating fuzzy quantification techniques, our framework is able to represent relevant quantitative process information with some degree of uncertainty present on it and describe it in natural language involving uncertain terms. A real application over the Aortic Stenosis Integrated Care Process of the University Hospital of Santiago de Compostela is presented, showcasing the potential of our framework for providing natural language descriptions of healthcare processes addressed to medical experts. Following the standards of D2T systems, manual human validation was conducted for the generated natural language descriptions by fifteen medical experts in Cardiology. Validation results are very positive, since a global average of 4.07/5.00 was achieved for questions related to understandability, usefulness and impact of the natural language descriptions on the medical experts work. More precisely, results indicate i) that the modality which conveyed the information most efficiently was natural language ii) a very clear preference of texts over the usual graphic representation of process information as the way for conveying information to experts (4.28/5.00), and iii) natural language descriptions provide relevant and useful information about the process, allowing for its improvement.},
author = {Fontenla-Seco, Yago and Lama, Manuel and González-Salvado, Violeta and Peña-Gil, Carlos and Bugarín-Diz, Alberto},
address = {SAN DIEGO},
copyright = {2022 The Author(s)},
issn = {1532-0464},
journal = {Journal of biomedical informatics},
keywords = {Computer science ; Human beings ; Integrated delivery of health care ; Language ; Medical informatics ; Natural Language Processing ; Process mining ; Technology},
language = {eng},
pages = {104033-104033},
publisher = {Elsevier Inc},
title = {A framework for the automatic description of healthcare processes in natural language: Application in an aortic stenosis integrated care process},
volume = {128},
year = {2022},
}

@incollection{Valero-RamonZoe2021IPMf,
abstract = {In this chapter we analyse how interactive models and Process Mining can be used for creating Dynamic Risk Models as a new way to stratify the patient’s behaviour with chronic conditions. Chronic conditions are long duration diseases that require ongoing management over a period of years or decades, so individuals’ behaviour should be taken into consideration. This is now possible thanks to the enormous amount of available data in medical systems. Current understanding of risk models for chronic diseases, relies on static snapshots of variables or measures, rather than ongoing, dynamic feedback loops of behaviour considering changes and different states. However, diseases are not static, they evolve towards different destinations, especially when talking about chronic health problems. Following the Interactive Process Mining paradigm, it is proposed a method for discovering different dynamic risk models for chronic diseases, based on the stratification of individuals’ behaviour. As a result, there were created two different IPIs for two chronic conditions, obesity and hypertension, with the goal of understanding diseases dynamic processes.},
author = {Valero-Ramon, Zoe and Fernandez-Llatas, Carlos and Fernandez-Llatas, Carlos},
address = {Cham},
booktitle = {Interactive Process Mining in Healthcare},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030539924},
issn = {1431-1917},
keywords = {Obesity ; Process mining},
language = {eng},
pages = {243-266},
publisher = {Springer International Publishing},
series = {Health Informatics},
title = {Interactive Process Mining for Discovering Dynamic Risk Models in Chronic Diseases},
year = {2021},
}

@article{AkterRuksana2016Pmfs,
abstract = {Process mining has been gaining increasing attention. In this paper, using a dataset which contains students' time series of activities during six sessions of digital electronics laboratory, we tried to get a reasonable or understandable process model to compare the behavior of the high score students and low score students and find out that these two type of students have different process model which probably caused them to get high or low scores},
author = {Akter, Ruksana and Chung, Yoojin},
address = {Koganei},
copyright = {Copyright 2017 Elsevier B.V., All rights reserved.},
issn = {1343-4500},
journal = {International Information Institute (Tokyo). Information},
keywords = {Data mining ; Digital electronics ; Education ; Heuristic ; Knowledge management ; Laboratories ; Learning ; Process mining ; Research ; Students ; Time Factors},
language = {eng},
number = {11},
pages = {5099-5106},
publisher = {International Information Institute},
title = {Process models for students according to scores},
volume = {19},
year = {2016},
}

@incollection{RibeiroJoel2022RDoV,
abstract = {Geolocation data is fundamental to businesses relying on vehicles such as logistics and transportation. With the advance of the technology, collecting geolocation data become increasingly accessible and affordable, which raised new opportunities for business intelligence. This paper addresses the application of geolocation data for monitoring logistics processes, namely for detecting vehicle-based operations in real time. A stream of geolocation entries is used for inferring stationary events. Data from an international logistics company is used as a case study, in which operations of loading/unloading of goods are not only identified but also quantified. The results of the case study demonstrate the effectiveness of the solution, showing that logistics operations can be inferred from geolocation data. Further meaningful information may be extracted from these inferred operations using process mining techniques.},
author = {Ribeiro, Joel and Tavares, Jorge and Fontes, Tânia and Ferreira, Joao C and Kocian, Alexander and Martins, Ana Lúcia and Martins, Ana Lúcia and Ferreira, Joao C and Kocian, Alexander},
address = {Switzerland},
booktitle = {Intelligent Transport Systems},
copyright = {ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2022},
isbn = {9783030976026},
issn = {1867-8211},
language = {eng},
pages = {192-205},
publisher = {Springer International Publishing AG},
series = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
title = {Real-Time Detection of Vehicle-Based Logistics Operations},
volume = {426},
year = {2022},
}

@article{KoschmiderAgnes2022Ccop,
abstract = {The combination of machine learning techniques with process analytics like process mining might even significantly elevate novel insights into time series data collections. To efficiently analyze time series by process mining and to convey confidence into the analysis result, requires bridging challenges. The purpose of this article is to discuss these challenges and to present initial solutions.},
author = {Koschmider, Agnes and Oppelt, Natascha and Hundsdörfer, Marie},
address = {Berlin/Heidelberg},
copyright = {The Author(s) 2022},
issn = {0170-6012},
journal = {Informatik-Spektrum},
keywords = {Computer input-output equipment ; Computer science ; Computers ; Machine learning ; Time Factors},
language = {eng},
number = {4},
pages = {223-228},
publisher = {Springer Berlin Heidelberg},
title = {Confidence-driven communication of process mining on time series},
volume = {45},
year = {2022},
}

@article{YadavRanjeet2023SPaM,
abstract = {Adoption of digital twin (DT) in smart factories, which simulates an actual system that is manufacturing conditions and updates them in real-time, increased the output and decreased the costs and energy use which were some ways that this manifested. Fast-changing consumer demands have caused a sharp increase in factory transition in addition to producing fewer life cycles of a product. Such scenarios cannot be handled by conventional simulation and modeling techniques; we suggest a general framework for automating the creation of simulation models that are data-driven as the foundation for smart factory DTs. Our proposed framework stands out thanks to its data-driven methodology, which takes advantage of recent advances in machine learning and techniques for process mining, constant model validation, and updating. The framework's objective is to completely define and reduce the requirement for specialist knowledge to get the appropriate simulation models. A case study is used to demonstrate our framework.},
author = {Yadav, Ranjeet and Roopa, Y. Mohana and Lavanya, M. and Ramesh, J. V. N. and Chitra, N. Thulasi and Babu, Gadde Raghu},
address = {Singapore},
copyright = {The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd 2023. Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.},
issn = {2662-995X},
journal = {SN computer science},
keywords = {Algorithms ; Artificial intelligence ; Big data ; Cloud computing ; Computer science ; Data Collection ; Decision making ; Energy consumption ; Factories ; Industry 4.0 ; Internet of things ; Machine learning ; Planning ; Vision},
language = {eng},
number = {5},
pages = {561-},
publisher = {Springer Nature Singapore},
title = {Smart Production and Manufacturing System Using Digital Twin Technology and Machine Learning},
volume = {4},
year = {2023},
}

@article{NadimKarim2023Ddca,
abstract = {The complexity of industrial processes imposes a lot of challenges in building accurate and representative causal models for abnormal events diagnosis, control and maintenance of equipment and process units. This paper presents an innovative data-driven causality modeling approach using interpretable machine learning and process mining techniques, in addition to human expertise, to efficiently and automatically capture the complex dynamics of industrial systems. The approach tackles a significant challenge in the causality analysis community, which is the discovery of high-level causal models from low-level continuous observations. It is based on the exploitation of event data logs by analyzing the dependency relationships between events to generate accurate multi-level models that can take the form of various state-event diagrams. Highly accurate and trustworthy patterns are extracted from the original data using interpretable machine learning integrated with a model enhancement technique to construct event data logs. Afterward, the causal model is generated from the event log using the inductive miner technique, which is one of the most powerful process mining techniques. The causal model generated is a Petri net model, which is used to infer causality between important events as well as a visualization tool for real-time tracking of the system’s dynamics. The proposed causality modeling approach has been successfully tested based on a real industrial dataset acquired from complex equipment in a Kraft pulp mill located in eastern Canada. The generated causality model was validated by ensuring high model fitness scores, in addition to the process expert’s validation of the results.},
author = {Nadim, Karim and Ragab, Ahmed and Ouali, Mohamed-Salah},
address = {New York},
copyright = {Her Majesty the Queen in Right of Canada as Represented by the Minister of Natural Resources 2022. corrected publication 2022},
issn = {0956-5515},
journal = {Journal of intelligent manufacturing},
keywords = {Automatic control ; Causality ; Computer science ; Control ; Data Analysis ; Engineering ; Implements ; Machine learning ; Machinery ; Mechatronics ; Modeling ; Petri nets ; Robotics ; Technology},
language = {eng},
number = {1},
pages = {57-83},
publisher = {Springer US},
title = {Data-driven dynamic causality analysis of industrial systems using interpretable machine learning and process mining},
volume = {34},
year = {2023},
}

@inproceedings{AdamsJanNiklas2022AFfa,
abstract = {Traditional process mining techniques take event data as input where each event is associated with exactly one object. An object represents the instantiation of a process. Object-centric event data contain events associated with multiple objects expressing the interaction of multiple processes. As traditional process mining techniques assume events associated with exactly one object, these techniques cannot be applied to object-centric event data. To use traditional process mining techniques, object-centric event data are flattened by removing all object references but one. The flattening process is lossy, leading to inaccurate features extracted from flattened data. Furthermore, the graph-like structure of object-centric event data is lost when flattening. In this paper, we introduce a general framework for extracting and encoding features from object-centric event data. We calculate features natively on the object-centric event data, leading to accurate measures. Furthermore, we provide three encodings for these features: tabular, sequential, and graph-based. While tabular and sequential encodings have been heavily used in process mining, the graph-based encoding is a new technique preserving the structure of the object-centric event data. We provide six use cases: a visualization and a prediction use case for each of the three encodings. We use explainable AI in the prediction use cases to show the utility of both the object-centric features and the structure of the sequential and graph-based encoding for a predictive model.},
author = {Adams, Jan Niklas and Park, Gyunam and Levich, Sergej and Schuster, Daniel and van der Aalst, Wil M. P. and Yao, Lina and Troya, Javier and Medjahed, Brahim and Fernández, Pablo and Ruiz-Cortés, Antonio and Piattini, Mario},
address = {Cham},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {3031209834},
issn = {0302-9743},
keywords = {Machine learning},
language = {eng},
pages = {36-53},
publisher = {Springer Nature Switzerland},
title = {A Framework for Extracting and Encoding Features from Object-Centric Event Data},
volume = {13740},
year = {2022},
}

@incollection{ValdésJulioJ.2020APMA,
abstract = {This paper presents a discussion of the potential of Process Mining for the analysis of general processes involving the time variation of magnitudes given by real-valued variables. These scenarios are common in a broad variety of domains, like natural and life sciences, engineering, and many others beyond business processes, where, in general, complex systems are observed and monitored using sensor data, producing time-series information. Two approaches are presented to construct event logs for such types of problems and one of them is applied to a real-world case (monitoring the F10.7 cm electromagnetic flux produced by the Sun). The results obtained with the Fuzzy Miner and the Multi-Objective Evolutionary Tree Miner algorithms successfully exposed the differences in the internal structure of the F10.7 cm series between Solar cycles. For this application, Process Mining proved to be a valuable tool for analyzing the rhythm of solar activity and how it is changing. The approach introduces here is general and could be used in the analysis of data from a broad variety of time-dependent information from many domains.},
author = {Valdés, Julio J. and Céspedes-González, Yaimara and Tapping, Kenneth and Molero-Castillo, Guillermo},
address = {Switzerland},
booktitle = {Advances in Intelligent Systems and Computing},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030630881},
issn = {2194-5357},
keywords = {Machine learning ; Process mining},
language = {eng},
pages = {379-392},
publisher = {Springer International Publishing AG},
series = {Advances in Intelligent Systems and Computing},
title = {A Process Mining Approach to the Analysis of the Structure of Time Series},
volume = {1289},
year = {2020},
}

@incollection{KnochSönke2020VUTE,
abstract = {Manual activities are often hidden deep down in discrete manufacturing processes. To analyze and optimize such processes, process discovery techniques allow the mining of the actual process behavior. Those techniques require the availability of complete event logs representing the execution of manual activities. Related works about collecting such information from sensor data unobtrusively for the worker are rare. Papers either address the sensor-based recognition of activities or focus on the process discovery part using process mining-compatible data sets. This paper builds on previous works to provide a solution on how execution-level information can be extracted from videos in manual assembly. The test bed consists of an assembly workstation equipped with a single RGB camera. A neural network-based real-time object detector delivers the input for an algorithm, which generates trajectories reflecting the movement paths of the worker’s hands. Those trajectories are automatically assigned to work steps using hierarchical clustering of similar behavior with dynamic time warping. The system has been evaluated in a task-based study with ten participants in a laboratory under realistic conditions. The generated logs have been loaded into the process mining toolkit ProM to discover the underlying process model and to measure the system’s performance using conformance checking.},
author = {Knoch, Sönke and Ponpathirkoottam, Shreeraman and Schwartz, Tim and Ghidini, Chiara and Dumas, Marlon and Fahland, Dirk and Becker, Jörg and Fahland, Dirk and Ghidini, Chiara and Dumas, Marlon and Becker, Jörg},
address = {Switzerland},
booktitle = {Business Process Management},
copyright = {Springer Nature Switzerland AG 2020},
isbn = {3030586650},
issn = {0302-9743},
keywords = {Computer vision ; Industry 4.0 ; Process mining},
language = {eng},
pages = {291-308},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Video-to-Model: Unsupervised Trace Extraction from Videos for Process Discovery and Conformance Checking in Manual Assembly},
volume = {12168},
year = {2020},
}

@inproceedings{YanWang2017Atfm,
abstract = {Mining a discrete event simulation model from data has always been a big challenge, which is related to the problem of system inference in systems theory. D2FD (Data to Fuzzy-DEVS model) method can be used to discover a discrete event simulation model. This method not only provides a way of data mining but also integrates process mining with the modularity, frequency, timing aspects and event data. This paper presents a mature tool applying D2FD method. This tool is implemented as an available and dedicated plug-in within the open-source process mining toolkit ProM. The simulation tool SimStudio is embedded in this plug-in and it can simulate Fuzzy-DEVS atomic and coupled model. Two case studies of real life processes, taken from Rabobank Group ICT and Dutch Employee Insurance Agency, are analyzed to evaluate this tool.},
author = {Yan Wang and Zacharewicz, Gregory and Traore, Mamadou Kaba and Chen, David},
booktitle = {2017 Winter Simulation Conference (WSC)},
copyright = {Copyright 2019 Elsevier B.V., All rights reserved.},
isbn = {1538634287},
issn = {0891-7736},
language = {eng},
pages = {3066-3077},
publisher = {IEEE},
title = {A tool for mining discrete event simulation model},
year = {2017},
}

@article{Rodriguez-FernandezVictor2021CCfT,
abstract = {This article tackles the problem of checking the conformance between a business process model and the data produced by its execution in cases where the data are not given as an event log, but as a set of time series containing the evolution of the variables involved in the process. Tasks in the process model are no longer restricted to the occurrence of a single event, and instead, they can be expressed as a set of temporal conditions about the values of the variables in the log. This causes a paradigm shift in conformance checking (and process mining at a more general level), and because of this, the formalization of both the data and the process model and the algorithms are here redesigned and adapted for this challenging perspective. To illustrate the effectiveness of our approach, an experimental evaluation on a real-world time-series log is carried out, highlighting the benefits of this change of paradigm.},
author = {Rodriguez-Fernandez, Victor and Trzcionkowska, Agnieszka and Gonzalez-Pardo, Antonio and Brzychczy, Edyta and Nalepa, Grzegorz J. and Camacho, David},
address = {PISCATAWAY},
copyright = {Copyright 2020 Elsevier B.V., All rights reserved.},
issn = {1551-3203},
journal = {IEEE transactions on industrial informatics},
keywords = {Algorithms ; Computer science ; Data mining ; Engineering ; Indexes ; Petri nets ; Process mining ; Task analysis ; Technology ; Time Factors},
language = {eng},
number = {2},
pages = {871-881},
publisher = {IEEE},
title = {Conformance Checking for Time-Series-Aware Processes},
volume = {17},
year = {2021},
}

@article{RizziWilliams2024Eppm,
abstract = {Explainability is motivated by the lack of transparency of black-box machine learning approaches, which do not foster trust and acceptance of machine learning algorithms. This also happens in the predictive process monitoring field, where predictions, obtained by applying machine learning techniques, need to be explained to users, so as to gain their trust and acceptance. In this work, we carry on a user evaluation on explanation approaches for predictive process monitoring aiming at investigating whether and how the explanations provided (i) are understandable; (ii) are useful in decision making tasks; (iii) can be further improved for process analysts with different predictive process monitoring expertise levels. The results of the user evaluation show that, although explanation plots are overall understandable and useful for decision making tasks for business process management users — with and without experience in predictive process monitoring — differences exist in the comprehension and usage of different plots, as well as in the way users with different predictive process monitoring expertise understand and use them.},
author = {Rizzi, Williams and Comuzzi, Marco and Di Francescomarino, Chiara and Ghidini, Chiara and Lee, Suhwan and Maggi, Fabrizio Maria and Nolte, Alexander},
address = {Cham},
copyright = {The Author(s) 2024},
issn = {2948-2178},
journal = {Process Science},
keywords = {Research},
language = {eng},
number = {1},
publisher = {Springer International Publishing},
title = {Explainable predictive process monitoring: a user evaluation},
volume = {1},
year = {2024},
}

@incollection{PourbafraniMahsa2022HBPS,
abstract = {Process mining techniques transfer historical data of organizations into knowledge for the purpose of process improvement. Most of the existing process mining techniques are “backward-looking” and provide insights w.r.t. historical event data. Foreseeing the future of processes and capturing the effects of changes without applying them to the real processes are of high importance. Current simulation techniques that benefit from process mining insights are either at detailed levels, e.g., Discrete Event Simulation (DES), or at aggregated levels, e.g., System Dynamics (SD). System dynamics represents processes at a higher degree of aggregation and accounts for the influence of external factors on the process. In this paper, we propose an approach for simulating business processes that combines both types of data-driven simulation techniques to generate holistic simulation models of processes. These techniques replicate processes at various levels and for different purposes, yet they both present the same process. SD models are used for strategical what-if analysis, whereas DES models are used for operational what-if analysis. It is critical to consider the effects of strategical decisions on detailed processes. We introduce a framework integrating these two simulation models, as well as a proof of concept to demonstrate the approach in practice.},
author = {Pourbafrani, Mahsa and van der Aalst, Wil M. P. and Franch, Xavier and Ralyté, Jolita and Guizzardi, Renata and Franch, Xavier and Ralyté, Jolita and Guizzardi, Renata},
address = {Switzerland},
booktitle = {Lecture Notes in Business Information Processing},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2022},
isbn = {3031057597},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {177-194},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Hybrid Business Process Simulation: Updating Detailed Process Simulation Models Using High-Level Simulations},
volume = {446},
year = {2022},
}

@article{XuHaifeng2020Uppm,
abstract = {BackgroundAlthough clinical guidelines provide the best practice for medical activities, there are some limitations in using clinical guidelines to assistant decision-making in practical application, such as long update cycle and low compliance of doctors with the guidelines. Driven by data of actual cases, process mining technology provides the possibility to remedy these shortcomings of clinical guidelines.MethodsWe propose a clinical decision support method using predictive process monitoring, which could be complementary with clinical guidelines, to assist medical staff with thrombolytic therapy decision-making for stroke patients. Firstly, we construct a labeled data set of 1191 cases to show whether each case actually need thrombolytic therapy, and whether it conform to the clinical guidelines. After prefix extraction and filtering the control flow of completed cases, the sequences with data flow are encoded, and corresponding prediction models are trained.ResultsCompared with the labeled results, the average accuracy of our prediction models for intravenous thrombolysis and arterial thrombolysis on the test set are 0.96 and 0.91, and AUC are 0.93 and 0.85 respectively. Compared with the recommendation of clinical guidelines, the accuracy, recall and AUC of our predictive models are higher.ConclusionsThe performance and feasibility of this method are verified by taking thrombolytic decision-making of patients with ischemic stroke as an example. When the clinical guidelines are not applicable, doctors could be provided with assistant decision-making by referring to similar historical cases using predictive process monitoring.},
author = {Xu, Haifeng and Pang, Jianfei and Yang, Xi and Li, Mei and Zhao, Dongsheng},
address = {LONDON},
copyright = {Copyright 2020 Elsevier B.V., All rights reserved.},
issn = {1472-6947},
journal = {BMC medical informatics and decision making},
keywords = {Administration Intravenous ; Contraindications ; Data mining ; Decision making ; Decision Support Systems Clinical ; Disabilities ; Evidence-based medicine ; Human beings ; Information storage and retrieval systems ; Ischemia ; Ischemic Stroke ; Medical informatics ; Medical personnel ; Monitoring ; Patients ; Physicians ; Practice Guidelines as Topic ; Research ; Stroke ; Telecommunication in medicine ; Thrombolytic therapy},
language = {eng},
number = {Suppl 3},
pages = {120-10},
publisher = {Springer Nature},
title = {Using predictive process monitoring to assist thrombolytic therapy decision-making for ischemic stroke patients},
volume = {20},
year = {2020},
}

@inproceedings{KamalaB.2022PMaD,
abstract = {Process mining is a new budding study in recent years which uses event logs and data. It is widely used in business organizations and it helps to improve the understanding of business processes, based on data. When a business process integrated with information systems provides the basis for new approach in data analysis. Process mining has a very good relationship with deep learning models that enables a strong relationship between business process management and business intelligence approach. Since the event data is available for process discovery and conformance checking techniques, process mining focuses on the entire process model. Process mining monitors and improves the real process by mining facts from event logs. While extracting knowledge there is no delay in today's information systems. The mining process models are used in various analysis. By applying deep learning techniques like deep neural networks and long short-term memory, risk management in a business process has been easily tracked and visualizing different activities involved in process prediction is also possible. Long Short-Term Memory of deep neural networks will be used for industrial process optimization, process improvement and process discovery in a Chemical Processes. It is well-suited to classify, process and predict time series given time lags of unknown duration. The revealed process models can be used for a large variety of analysis purposes. Deep fuzzy neural network framework that integrates the hidden feature of the CNN model and the LSTM model is proposed to improve the forecasting accuracy of business process outcome prediction.},
author = {Kamala, B. and Latha, B.},
booktitle = {2022 International Conference on Communication, Computing and Internet of Things (IC3IoT)},
isbn = {1665479957},
keywords = {Data mining ; Process mining},
language = {eng},
pages = {1-4},
publisher = {IEEE},
title = {Process Mining and Deep Neural Network approach for the Prediction of Business Process Outcome},
year = {2022},
}

@incollection{HalaškaMichal2020MMSa,
abstract = {Business models raised on popularity in recent years among both researchers and practitioners. However, operational research in the area of business modelling is limited, especially regarding business processes. Greater focus is nowadays put on strategic layer and other perspectives of business models. Thus, the aim of the paper is to implement business model in the form of messaged multi-agent system at the operational layer with process perspective as building block of the model. This approach strengthens the innovative capabilities of business models. In our paper, first, correspondent literature review is presented. The focus is given on investigation of relations of business models and business process management discipline. Process perspective is emphasized because it is naturally capable of integration of other perspectives, e.g. dynamic perspective, revenue model, business logic, resource-based view, etc. Second, it is shown, how can messaged multi-agent system be used as a supporting tool incorporating business model dynamics through innovation, while integrating different business model perspectives. As a result, messaged multi-agent system is introduced. It represents unique implementation of a business model reflecting on a trading company, where interactions between process participants are mediated through messages. The presented results involve comparison of two business models’ implementations, where the redesigned business model incorporates changes in pricing of the product and marketing campaigning. Process mining method and statistics are used to comment on the outcomes. Process mining plays a crucial role as it is used for validation of business logic, discovery of business process model and comparative analysis of both business models.},
author = {Halaška, Michal and Šperka, Roman and Sperka, Roman and Jezic, Gordan and Chen-Burger, Yun-Heh Jessica and Jain, Lakhmi C and Howlett, Robert J and Kusek, Mario and Kusek, Mario and Jezic, Gordan and Šperka, Roman and Jain, Lakhmi C. and Chen-Burger, Yun-Heh Jessica and Howlett, Robert J.},
address = {Singapore},
booktitle = {Agents and Multi-Agent Systems: Technologies and Applications 2019},
copyright = {Springer Nature Singapore Pte Ltd. 2020},
isbn = {9811386781},
issn = {2190-3018},
keywords = {Process mining},
language = {eng},
pages = {355-365},
publisher = {Springer Singapore Pte. Limited},
series = {Smart Innovation, Systems and Technologies},
title = {Messaged Multi-agent System as a Tool for Strengthening Innovative Capabilities of Business Models},
volume = {148},
year = {2020},
}

@article{Ramirez-AlcocerUlisesManuel2023ADLA,
abstract = {In this paper, we propose a deep learning-based approach to predict the next event in hospital organizational process models following the guidance of predictive process mining. This method provides value for the planning and allocating of resources since each trace linked to a case shows the consecutive execution of events in a healthcare process. The predictive model is based on a long short-term memory (LSTM) neural network that achieves high accuracy in the training and testing stages. In addition, a framework to implement the LSTM neural network is proposed, comprising stages from the preprocessing of the raw data to selecting the best LSTM model. The effectiveness of the prediction method is evaluated through four real-life event logs that contain historical information on the execution of the processes of patient transfer orders between hospitals, sepsis care cases, billing of medical services, and patient care management. In the test stage, the LSTM model reached values of 0.98, 0.91, 0.85, and 0.81 in the accuracy metric, and in the evaluation of the prediction of the next event using the 10-fold cross-validation technique, values of 0.94, 0.88, 0.84, and 0.81 were obtained for the four previously mentioned event logs. In addition, the performance of the LSTM prediction model was evaluated with the precision, recall, F1-score, and area under the receiver operating characteristic (ROC) curve (AUC) metrics, obtaining high scores very close to 1. The experimental results suggest that the proposed method achieves acceptable measures in predicting the next event regardless of whether an input event or a set of input events is used.},
author = {Ramirez-Alcocer, Ulises Manuel and Tello-Leal, Edgar and Romero, Gerardo and Macías-Hernández, Bárbara A.},
address = {Basel},
copyright = {Copyright 2023 Elsevier B.V., All rights reserved.},
issn = {2078-2489},
journal = {Information},
keywords = {Behavior ; Electronic Health Records ; Hospitals ; Information storage and retrieval systems ; Medical care ; Methodology ; Methods ; Patients ; Public health ; Taiwan ; Time Factors},
language = {eng},
number = {9},
pages = {508-},
publisher = {MDPI AG},
title = {A Deep Learning Approach for Predictive Healthcare Process Monitoring},
volume = {14},
year = {2023},
}

@incollection{cdi_springer_books_10_1007_978_3_031_61057_8_5,
abstract = {Predictive process monitoring plays a critical role in process mining by predicting the dynamics of ongoing processes. Recent trends employ deep learning techniques that use event sequences to make highly accurate predictions. However, this focus often overshadows the significant advantages of lightweight, transparent algorithms. This study explores the potential of traditional regression algorithms, namely kNN, SVM, and RF, enhanced by event time feature engineering. We integrate existing and novel time-related features to augment these algorithms and compare their performance against the well-known LSTM network. Our results show that these enhanced lightweight models not only compete with LSTM in terms of predictive accuracy but also excel in scenarios requiring online, real-time decision-making and explanation. Furthermore, despite incorporating additional feature extraction processes, these algorithms maintain superior computational efficiency compared to their deep learning counterparts, making them more viable for time-critical and resource-constrained environments.},
author = {Oyamada, Rafael Seidi and Tavares, Gabriel Marques and Junior, Sylvio Barbon and Ceravolo, Paolo and Soffer, Pnina and Mouratidis, Haralambos and Guizzardi, Giancarlo and Santoro, Flavia},
address = {Cham},
booktitle = {Advanced Information Systems Engineering},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {9783031610561},
issn = {0302-9743},
keywords = {Process mining},
language = {eng},
pages = {71-86},
publisher = {Springer Nature Switzerland},
series = {Lecture Notes in Computer Science},
title = {Enhancing Predictive Process Monitoring with Time-Related Feature Engineering},
}

@incollection{MusaTahaniHusseinAbu2024PoNE,
abstract = {Business Process Mining is considered one of the merging fields that focusses on analyzing Business Process Models (BPM), by extracting knowledge from event logs generated by various information systems, for the sake of auditing, monitoring, and analysis of business activities for future improvement and optimization throughout the entire lifecycle of such processes, from creation to conclusion. In this work, Long Short-Term Memory (LSTM) Neural Network was utilized for the prediction of the execution of cases, through training and testing the model on event traces extracted from event logs related to a given business process model. From the initial results we obtained, our model was able to predict the next activity in the sequence with high accuracy. The approach consisted of three phases: preprocessing the logs, classification, and categorization and all the activities related to implementing the LSTM model, including network design, training, and model selection. The predictive analysis achieved in this work can be extended to include anomaly detection capabilities, to detect any anomalous events or activities captured in the event logs.},
author = {Musa, Tahani Hussein Abu and Bouras, Abdelaziz and Nyffenegger, Felix and Harik, Ramy and Rivest, Louis and Danjou, Christophe and Bouras, Abdelaziz},
address = {Cham},
booktitle = {Product Lifecycle Management. Leveraging Digital Twins, Circular Economy, and Knowledge Management for Sustainable Innovation},
copyright = {IFIP International Federation for Information Processing 2024},
isbn = {3031625811},
issn = {1868-4238},
language = {eng},
pages = {210-220},
publisher = {Springer Nature Switzerland},
series = {IFIP Advances in Information and Communication Technology},
title = {Prediction of Next Events in Business Processes: A Deep Learning Approach},
year = {2024},
}


@incollection{PasquadibisceglieVincenzo2020PPMM,
abstract = {Nowadays predictive process mining is playing a fundamental role in the business scenario as it is emerging as an effective means to monitor the execution of any business running process. In particular, knowing in advance the next activity of a running process instance may foster an optimal management of resources and promptly trigger remedial operations to be carried out. The problem of next activity prediction has been already tackled in the literature by formulating several machine learning and process mining approaches. In particular, the successful milestones achieved in computer vision by deep artificial neural networks have recently inspired the application of such architectures in several fields. The original contribution of this work consists of paving the way for relating computer vision to process mining via deep neural networks. To this aim, the paper pioneers the use of an RGB encoding of process instances useful to train a 2-D Convolutional Neural Network based on Inception block. The empirical study proves the effectiveness of the proposed approach for next-activity prediction on different real-world event logs.},
author = {Pasquadibisceglie, Vincenzo and Appice, Annalisa and Castellano, Giovanna and Malerba, Donato and Ghidini, Chiara and Dumas, Marlon and Fahland, Dirk and Becker, Jörg and Fahland, Dirk and Ghidini, Chiara and Dumas, Marlon and Becker, Jörg},
address = {Switzerland},
booktitle = {Business Process Management Forum},
copyright = {Springer Nature Switzerland AG 2020},
isbn = {3030586375},
issn = {1865-1348},
keywords = {Computer vision},
language = {eng},
pages = {176-192},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Predictive Process Mining Meets Computer Vision},
volume = {392},
year = {2020},
}

@article{AkçapınarGökhan2020Atrb,
abstract = {Öz: Bu çalışmada üniversite öǧrencilerinin ödev gönderme davranışları ile ders başarıları arasındaki ilişkinin incelenmesi amaçlanmıştır. Bu amaçla, bir devlet üniversitesinde İşletim Sistemleri ve Uygulamaları dersine kayıtlı 75 öǧrencinin Moodle öǧrenme yönetim sistemi üzerinden dersin dördüncü haftasında verilen bir ödevi gönderme davranışları analiz edilmiştir. Aynı zamanda farklı ödev gönderme davranışı sergileyen öǧrenciler dönem sonu notları açısından da analiz edilmiştir. Analiz aşamasında, öǧrencilerin ödev gönderirken izledikleri adımlar sıralı olarak belirlenmiş ve kümeleme analizi yardımı ile benzer örüntü sergileyen öǧrenciler gruplara ayrılmıştır. Aynı zamanda süreç madenciliǧi analizi kullanılarak farklı gruplardaki öǧrencilerin ödev gönderme süreçleri detaylı olarak analiz edilmiştir. Yapılan analizler, öǧrencilerin ödev gönderme davranışlarına göre üç farklı gruba ayrılabileceǧini göstermiştir. Ders başarısı açısından bakıldıǧında ise ödevi gönderen öǧrencilerin önemli bir bölümünün dersten başarılı olduǧu gözlemlenirken, ödev gönderiminde bulunmayan öǧrencilerin önemli bir bölümünün dersten başarısız olduǧu görülmüştür. Elde edilen bulgular, dersten başarısız olma ihtimali yüksek olan öǧrencilerin erken haftalarda belirlenmesinde ve bu öǧrencilere yönelik olası müdahalelerin tasarlanmasında yol gösterici olacaktır.},
author = {Akçapınar, Gökhan and Kokoç, Mehmet},
address = {Gurgaon},
copyright = {Copyright 2020 Elsevier B.V., All rights reserved.},
issn = {1309-4653},
journal = {Turkish journal of computer and mathematics education},
keywords = {Cluster analysis ; Multivariate analysis ; Process mining ; Students},
language = {eng},
number = {2},
pages = {386-401},
publisher = {Ninety Nine Publication},
title = {Analyzing the relationship between student's assignment submission behaviors and course achievement through process mining analysis},
volume = {11},
year = {2020},
}

@incollection{PfeifferPeter2024TvTE,
abstract = {Process mining offers powerful techniques to analyze real-world event data, aiming to improve processes. Typically, the data is stored and examined in event logs as traces, where each trace contains the sequence of events pertaining to a specific process case. A case can, e.g., represent the management of a customer request or the sequence of events from ordering to delivering a product to a customer in online retail businesses. While this approach allows to analyze and gain insights from complex event data, it also isolates events that in reality are correlated, potentially concealing important process behavior. In this paper, we motivate and conceptualize the approach to describe the observations generated by the underlying system as a single event sequence that is ordered as being executed. We study and compare how much the event order and trace notion affect the entropy rates of different real-life processes. Further, we investigate how predictable next activities in event sequences are. Our study indicates that ordering the events as executed does not necessarily increase the entropy rates of the process. We discuss these findings and their implications for future research.},
author = {Pfeiffer, Peter and Fettke, Peter and Jans, Mieke and Rosemann, Michael and Resinas, Manuel and Marrella, Andrea and Marrella, Andrea and Jans, Mieke and Rosemann, Michael and Resinas, Manuel},
address = {Switzerland},
booktitle = {Business Process Management Forum},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {9783031704178},
issn = {1865-1348},
keywords = {Entropy},
language = {eng},
pages = {72-89},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {Trace vs. Time: Entropy Analysis and Event Predictability of Traceless Event Sequencing},
volume = {526},
year = {2024},
}

@article{Valero-RamonZoe2020IPIf,
abstract = {World Health Organisation defines overweight and obesity as abnormal or excessive fat accumulation that represents a risk to health. Obesity and overweight are associated with increased risk of comorbidities and social problems that negatively impact quality of life. Due to the complexity of the problems, it is necessary to classify obesity based on a set of factors rather than a simple increase in body weight. The objectives of this work were to examine BMI and data available from comorbidities associated to obesity, from a dynamic perspective thanks to the use of process mining tools, in order to obtain patterns of patients’ behaviours. On the other hand, to develop a set of human-readable and contextualised interactive process indicators (iPIs) in the field of obesity, related conditions support health professionals to interact with the process. Modelling iPIs as enhanced views will help the professionals to better perceive of these processes. Professionals will monitor the patient’s progress iteratively and will interact with the system to fine-tune interventions and treatments. The developed strategy can support both the characterisation of general process-based PI and the analysis of individual and personalised aspects of the processes going from general to individual. This method was applied to real data extracted from a tertiary hospital in Spain.},
author = {Valero-Ramon, Zoe and Fernandez-Llatas, Carlos and Martinez-Millana, Antonio and Traver, Vicente},
address = {Berlin, Heidelberg},
copyright = {Springer-Verlag GmbH Germany, part of Springer Nature 2020},
isbn = {9783662611128},
issn = {1860-949X},
journal = {Advanced Computational Intelligence in Healthcare-7},
keywords = {Obesity ; Process mining},
language = {eng},
pages = {45-64},
publisher = {Springer Berlin Heidelberg},
title = {Interactive Process Indicators for Obesity Modelling Using Process Mining},
year = {2020},
}

@incollection{PourbafraniMahsa2021EPFf,
abstract = {Most process mining techniques are backward-looking, i.e., event data are used to diagnose performance and compliance problems. The combination of process mining and simulation allows for forward-looking approaches to answer “What if?” questions. However, it is difficult to create fine-grained simulation models that describe the process at the level of individual events and cases in such a way that reality is captured well. Therefore, we propose to use coarse-grained simulation models (e.g., System Dynamics) that simulate processes at a higher abstraction level. Coarse-grained simulation provides two advantages: (1) it is easier to discover models that mimic reality, and (2) it is possible to explore alternative scenarios more easily (e.g., brainstorming on the effectiveness of process interventions). However, this is only possible by bridging the gap between low-level event data and the coarse-grained process data needed to create higher-level simulation models where one simulation step may correspond to a day or week. This paper provides a general approach and corresponding tool support to bridge this gap. We show that we can indeed learn System Dynamics models from standard event data.},
author = {Pourbafrani, Mahsa and van der Aalst, Wil M. P. and Sadiq, Shazia and Teniente, Ernest and La Rosa, Marcello and Teniente, Ernest and La Rosa, Marcello and Sadiq, Shazia},
address = {Switzerland},
booktitle = {Advanced Information Systems Engineering},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {3030793818},
issn = {0302-9743},
keywords = {Process mining},
language = {eng},
pages = {125-140},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Extracting Process Features from Event Logs to Learn Coarse-Grained Simulation Models},
volume = {12751},
year = {2021},
}

@incollection{Rinderle-MaStefanie2021PAaP,
abstract = {Process automation and process mining are (interconnected) key technologies with respect to digital transformation. Hence, expectations are high, in particular, in challenging application domains such as manufacturing that combine systems, machines, sensors, and users. Moreover, manufacturing processes operate at a high level of collaboration, e.g. in inter-factory or cross-organizational settings. This paper investigates the following questions: 1) How to automate manufacturing processes? 2) What are the specifics with respect to the involvements of humans? 3) How do the automation strategies impact process mining options and vice versa? For 1), we discuss two starting positions in practice, i.e., legacy automation and greenfield automation. For 2), we discuss the range of automation options with respect to human involvement, i.e., non-interactive automation, robotic process automation, supportive process automation, and interactive process automation. For 3), the different automation settings and strategies are examined with respect to data collection and integration capabilities. Conversely, process mining is discussed as technology to further process automation in manufacturing. The paper builds on more than a decade of experience with process automation in manufacturing. We built an orchestration engine based on which 16 real-world manufacturing processes have been realized so far, resulting in various benefits for the companies such as traceability, flexibility, and sustainability. The investigation of the manufacturing domain also sheds light on other challenging scenarios with similar requirements such as health care and logistics.},
author = {Rinderle-Ma, Stefanie and Mangler, Juergen and Reichert, Manfred and Wynn, Moe Thandar and Polyvyanyy, Artem and Van Looy, Amy and Polyvyanyy, Artem and Van Looy, Amy and Reichert, Manfred and Wynn, Moe Thandar},
address = {Switzerland},
booktitle = {Business Process Management},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030854683},
issn = {0302-9743},
keywords = {Process mining},
language = {eng},
pages = {3-14},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Process Automation and Process Mining in Manufacturing},
volume = {12875},
year = {2021},
}

@incollection{LashkevichKatsiaryna2023DoIO,
abstract = {Overprocessing is a source of waste that occurs when unnecessary work is performed in a process. Overprocessing is often found in application-to-approval processes since a rejected application does not add value, and thus, work that leads to the rejection constitutes overprocessing. Analyzing how the knock-out checks are executed can help analysts to identify opportunities to reduce overprocessing waste and time. This paper proposes an interpretable process mining approach for discovering improvement opportunities in the knock-out checks and recommending redesigns to address them. Experiments on synthetic and real-life event logs show that the approach successfully identifies improvement opportunities while attaining a performance comparable to black-box approaches. Moreover, by leveraging interpretable machine learning techniques, our approach provides further insights on knock-out check executions, explaining to analysts the logic behind the suggested redesigns. The approach is implemented as a software tool and its applicability is demonstrated on a real-life process.},
author = {Lashkevich, Katsiaryna and Mediavilla Ponce, Lino Moises and Camargo, Manuel and Milani, Fredrik and Dumas, Marlon and Opdahl, Andreas L and Nurcan, Selmin and Tsohou, Aggeliki and Mouratidis, Haralambos and Nurcan, Selmin and Opdahl, Andreas L. and Mouratidis, Haralambos and Tsohou, Aggeliki},
address = {Switzerland},
booktitle = {Lecture Notes in Business Information Processing},
copyright = {The Author(s) 2023, Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.},
isbn = {9783031330797},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {381-397},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {Discovery of Improvement Opportunities in Knock-Out Checks of Business Processes},
volume = {476},
year = {2023},
}

@incollection{FrancisDeenaP.2021TDDT,
abstract = {The adoption of a digital twin for a smart factory offers several advantages, such as improved production and reduced costs, and energy consumption. Due to the growing demands of the market, factories have adopted the reconfigurable manufacturing paradigm, wherein the structure of the factory is constantly changing. This situation presents a unique challenge to traditional modeling and simulation approaches. To deal with this scenario, we propose a generic data-driven framework for automated construction of digital twins for smart factories. The novel aspects of our proposed framework include a pure data-driven approach incorporating machine learning and process mining techniques, and continuous model improvement and validation.},
author = {Francis, Deena P. and Lazarova-Molnar, Sanja and Mohamed, Nader and Zydek, Dawid and Selvaraj, Henry and Chmaj, Grzegorz and Selvaraj, Henry and Zydek, Dawid and Chmaj, Grzegorz},
address = {Switzerland},
booktitle = {Lecture Notes in Networks and Systems},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {3030657957},
issn = {2367-3370},
keywords = {Machine learning ; Process mining},
language = {eng},
pages = {445-454},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Towards Data-Driven Digital Twins for Smart Manufacturing},
volume = {182},
year = {2021},
}

@incollection{CremeriusJonas2023CCPD,
abstract = {Process mining bridges the gap between process management and data science by utilizing process execution data to discover and analyse business processes. This data is represented in event logs, where each event contains attributes describing the process instance, the time the event has occurred, and much more. In addition to these generic event attributes, events contain domain-specific event attributes, such as a measurement of blood pressure in a healthcare environment. Taking a close look at those attributes, it turns out that the respective values change during a typical process quite frequently, hence we refer to them as dynamic event attributes. This paper studies change patterns of dynamic event attributes by recurring process activities in a given context. We have applied the technique on two real-world datasets, MIMIC-IV and Sepsis, representing hospital treatment processes, and show that the approach can provide novel insights. The approach is implemented in Python, based on the PM4Py framework.},
author = {Cremerius, Jonas and Weske, Mathias and Pérez, Francisca and Cabanillas, Cristina and Cabanillas, Cristina and Pérez, Francisca},
address = {Switzerland},
booktitle = {Intelligent Information Systems},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {9783031346736},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {1-8},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Context-Aware Change Pattern Detection in Event Attributes of Recurring Activities},
volume = {477},
year = {2023},
}

@incollection{RichterFlorian2021OOTO,
abstract = {Identifying structures in data is an essential step to enhance insights and understand applications. Clusters and anomalies are the basic building blocks for those structures and occur in various types. Clusters vary in shape and density, while anomalies occur as single-point outliers, contextual or collective anomalies. In online applications, clusters even have a higher complexity. Besides static clusters, which represent a persistent structure throughout the whole data stream, many clusters are dynamic, tend to drift and are only observable in certain time frames. Here, we propose OTOSO, a monitoring tool based on OPTICS. OTOSO is an anytime structure visualizer, that plots representations for density-based trace clusters in process event streams. It identifies temporal deviation clusters and visualizes them as a time-dependent graph. Each node represents a cluster of traces by size and density. Edges yield information about merging and splitting trace clusters. The aim is to provide an on-demand overview over the temporal deviation structure during the process execution. Not only for online applications, but also for static datasets, our approach yields insights about temporally limited occurrences of trace clusters, which are difficult to detect using a global clustering approach.},
author = {Richter, Florian and Maldonado, Andrea and Zellner, Ludwig and Seidl, Thomas and Leemans, Sander and Leopold, Henrik and Leemans, Sander and Leopold, Henrik},
address = {Switzerland},
booktitle = {Process Mining Workshops},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030726928},
issn = {1865-1348},
keywords = {Visualization},
language = {eng},
pages = {218-229},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {OTOSO: Online Trace Ordering for Structural Overviews},
volume = {406},
year = {2021},
}

@article{KimKwanghoonPio2023EAoT,
abstract = {In the research field of the automated process discovery and analysis, the purity of event log datasets ought to be a matter of vital importance to the success of discovering sound and exact process models. Moreover, there exist various types of anomalies that result in the discovery of inaccurate process models from the process enactment event log datasets. A peculiar one out of these anomalies, which is the core challenging issue of this paper, is the temporal activity-sequencing anomaly that critically affects the overall quality of the automated process discovery. This paper explores such event-log anomalies and noises produced by the special type of anomalies inevitably formed in the event-log preprocessing phase of the automated process discovery. More precisely, it implements an algorithmic approach that is able to detect and filter out those anomalies and noises in performing the automated process discovery. The author also carries out a series of experimental analyses by applying the implemented approach to the five datasets of process event logs available in the 4TU Center for Research Data.},
author = {Kim, Kwanghoon Pio},
address = {BASEL},
copyright = {Copyright 2023 Elsevier B.V., All rights reserved.},
issn = {2076-3417},
journal = {Applied sciences},
keywords = {Algorithms ; Automation ; Chemistry ; Engineering ; Materials science ; Mineral industries ; Noise ; Physical sciences ; Physics ; Process mining ; Research ; Technology},
language = {eng},
number = {5},
pages = {3143-},
publisher = {Mdpi},
title = {Experimental Analyses of Temporal Activity-Sequencing Anomalies in Process Mining},
volume = {13},
year = {2023},
}

@incollection{ZhongYinzheng2024PMAf,
abstract = {In this paper, we consider the applications of process mining in intrusion detection. We propose a novel process mining inspired algorithm to be used to preprocess data in intrusion detection systems (IDS). The algorithm is designed to process the network packet data and it works well in online mode for online intrusion detection. To test our algorithm, we used the CSE-CIC-IDS2018 dataset which contains several common attacks. The packet data was preprocessed with this algorithm and then fed into the detectors. We report on the experiments using the algorithm with different machine learning (ML) models as classifiers to verify that our algorithm works as expected; we tested the performance on anomaly detection methods as well and reported on the existing preprocessing tool CICFlowMeter for the comparison of performance.},
author = {Zhong, Yinzheng and Goulermas, John Y. and Lisitsa, Alexei and Yavorskiy, Rostislav and Kalenkova, Anna and Cavalli, Ana Rosa and Cavalli, Ana Rosa and Kalenkova, Anna and Yavorskiy, Rostislav},
address = {Switzerland},
booktitle = {Communications in Computer and Information Science},
copyright = {Springer Nature Switzerland AG 2024},
isbn = {3031504224},
issn = {1865-0929},
keywords = {Computer security ; Process mining},
language = {eng},
pages = {15-25},
publisher = {Springer International Publishing AG},
series = {Communications in Computer and Information Science},
title = {Process Mining Algorithm for Online Intrusion Detection System},
volume = {1559},
year = {2024},
}

@incollection{DunklReinhold2015AMfA,
abstract = {The majority of process mining techniques focuses on control flow. Decision Point Analysis (DPA) exploits additional data attachments within log files to determine attributes decisive for branching of process paths within discovered process models. DPA considers only single attribute values. However, in many applications, the process environment provides additional data in form of consecutive measurement values such as blood pressure or container temperature. We introduce the DPATS method as an iterative process for exploiting time series data by combining process and data mining techniques. The latter ranges from visual mining to temporal data mining techniques such as dynamic time warping and response feature analysis. The method also offers different approaches for incorporating time series data into log files in order to enable existing process mining techniques to be applied. Finally, we provide the simulation environment DPATSSim to produce log files and time series data. The DPATS method is evaluated based on application scenarios from the logistics and medical domain.},
author = {Dunkl, Reinhold and Rinderle-Ma, Stefanie and Grossmann, Wilfried and Anton Fröschl, Karl},
address = {Cham},
booktitle = {Information Systems Engineering in Complex Environments},
copyright = {Springer International Publishing Switzerland 2015},
isbn = {9783319192697},
issn = {1865-1348},
keywords = {Data mining ; Process mining},
language = {eng},
pages = {68-84},
publisher = {Springer International Publishing},
series = {Lecture Notes in Business Information Processing},
title = {A Method for Analyzing Time Series Data in Process Mining: Application and Extension of Decision Point Analysis},
volume = {204},
year = {2015},
}

@inproceedings{BobekSzymon2019Eikd,
abstract = {Interpretability of machine learning algorithms become an emerging research area over last decade. Most powerful algorithms such as deep neural networks, gradient boosting trees, deep reinforcement learning and other do not offer human-understandable justification of their decisions. However, such explanations are desired in high-risk domains (such as health, autonomous vehicles), and recently required by law (GDPR regulations in EU). Several methods were developed to assure that feature, with LIME and SHAP among most robust approaches. In this paper we focus on the issue of interpretable decision making in time series data streams. In our previous work we developed causal rule-mining algorithm that provided contrastive explanations via rule-based notation. We work on extending this work to exploit strengths of process mining and Bayesian networks to better assure counterfactual explanations.},
author = {Bobek, Szymon and Nalepa, Grzegorz J.},
booktitle = {2019 First International Conference on Societal Automation (SA)},
isbn = {9781728133454},
keywords = {Decision making ; Knowledge Discovery ; Machine learning ; Reinforcement learning},
language = {eng},
pages = {1-4},
publisher = {IEEE},
title = {Explainability in knowledge discovery from data streams},
year = {2019},
}

@incollection{WaisBeate2024TaEo,
abstract = {Decision mining algorithms discover decision points and the corresponding decision rules in business processes. So far, the evaluation of decision mining algorithms has focused on performance (e.g., accuracy), neglecting the impact of other criteria, e.g., understandability or consistency of the discovered decision model. However, performance alone cannot reflect if the discovered decision rules produce value to the user by providing insights into the process. Providing metrics to comprehensively evaluate the decision model and decision rules can lead to more meaningful insights and assessment of decision mining algorithms. In this paper, we examine the ability of different criteria from software engineering, explainable AI, and process mining that go beyond performance to evaluate decision mining results and propose metrics to measure these criteria. To evaluate the proposed metrics, they are applied to different decision algorithms on two synthetic and one real-life dataset. The results are compared to the findings of a user study to check whether they align with user perception. As a result, we suggest four metrics that enable a comprehensive evaluation of decision mining results and a more in-depth comparison of different decision mining algorithms. In addition, guidelines for formulating decision rules are presented.},
author = {Wais, Beate and Rinderle-Ma, Stefanie and Soffer, Pnina and Mouratidis, Haralambos and Guizzardi, Giancarlo and Santoro, Flavia},
address = {Cham},
booktitle = {Advanced Information Systems Engineering},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {9783031610561},
issn = {0302-9743},
keywords = {Evaluation ; Process mining ; Versification},
language = {eng},
pages = {403-419},
publisher = {Springer Nature Switzerland},
series = {Lecture Notes in Computer Science},
title = {Towards a Comprehensive Evaluation of Decision Rules and Decision Mining Algorithms Beyond Accuracy},
year = {2024},
}

@incollection{LepsienArvid2023APfM,
abstract = {Process mining has shown that it provides valuable insights in terms of uncovering bottlenecks and inefficiencies in processes or identifying tasks for automation. However, process mining techniques expect structured input data that is at a high (business) level of abstraction. Recently, the benefits of process mining for unstructured data which is at a much lower level of abstraction have been demonstrated, e.g., for IoT data or time series data. It can be expected that the demand for methods efficiently processing these kinds of data for process mining will continuously increase. Hence, in this paper, we present an approach that allows the translation of video data into higher-level, discrete event data, thus enabling existing process mining techniques to work on data tracked in videos. Particularly, we used a combination of object tracking, spatio-temporal action detection, and techniques for raising the abstraction level of events. The evaluation results show that meaningful event logs can be extracted from an unlabeled video dataset, validating both the implementation and the feasibility of our approach.},
author = {Lepsien, Arvid and Koschmider, Agnes and Kratsch, Wolfgang},
address = {Cham},
booktitle = {Business Process Management Forum},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {3031416228},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {196-213},
publisher = {Springer Nature Switzerland},
series = {Lecture Notes in Business Information Processing},
title = {Analytics Pipeline for Process Mining on Video Data},
volume = {490},
year = {2023},
}

@incollection{DixitPrabhakarM.2018DaIR,
abstract = {Many forms of data analysis require timestamp information to order the occurrences of events. The process mining discipline uses historical records of process executions, called event logs, to derive insights into business process behaviours and performance. Events in event logs must be ordered, typically achieved using timestamps. The importance of timestamp information means that it needs to be of high quality. To the best of our knowledge, no (semi-)automated support exists for detecting and repairing ordering-related imperfection issues in event logs. We describe a set of timestamp-based indicators for detecting event ordering imperfection issues in a log and our approach to repairing identified issues using domain knowledge. Lastly, we evaluate our approach implemented in the open-source process mining framework, ProM, using two publicly available logs.},
author = {Dixit, Prabhakar M. and Suriadi, Suriadi and Andrews, Robert and Wynn, Moe T. and ter Hofstede, Arthur H. M. and Buijs, Joos C. A. M. and van der Aalst, Wil M. P. and Reijers, Hajo A and Krogstie, John and Krogstie, John and Reijers, Hajo A.},
address = {Switzerland},
booktitle = {Advanced Information Systems Engineering},
copyright = {Springer International Publishing AG, part of Springer Nature 2018},
isbn = {3319915622},
issn = {0302-9743},
keywords = {Data Accuracy},
language = {eng},
pages = {274-290},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Detection and Interactive Repair of Event Ordering Imperfection in Process Logs},
volume = {10816},
year = {2018},
}

@incollection{WeberBarbara2024LDTD,
abstract = {The ongoing digitization of processes in all domains of everyday life driven by IT systems shows great potential for process automation, analysis, and optimization. In the last decade process mining has advanced to an important and mature discipline of computer science research and has been widely adopted in industry. More recently,—acknowledging the huge potential of digital trace data to study processes—process science has been introduced as an interdisciplinary field studying how processes unfold over time. This paper discusses the potential that arises when using digital trace data not only in the context of highly automated processes but also to investigate human-centered (work) processes and elaborates on associated challenges. Examples range from the semi-automated storage and production processes in a smart factory to healthcare processes to process analysts performing process mining tasks and software engineers reading software artifacts like source code and process models.},
author = {Weber, Barbara and Abbad-Andaloussi, Amine and Franceschetti, Marco and Seiger, Ronny and Völzer, Hagen and Zerbato, Francesca and Mannion, Mike and Kaindl, Hermann and Maciaszek, Leszek A.},
address = {Cham},
booktitle = {Evaluation of Novel Approaches to Software Engineering},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {9783031641817},
issn = {1865-0929},
language = {eng},
pages = {1-23},
publisher = {Springer Nature Switzerland},
series = {Communications in Computer and Information Science},
title = {Leveraging Digital Trace Data to Investigate and Support Human-Centered Work Processes},
year = {2024},
}

@article{PDF2024LCMf,
abstract = {In real business processes, low quality event logs due to outliers and missing values tend to degrade the performance of process mining related algorithms, which in turn affects the correct execution of decisions. In order to repair the missing values in event logs under the condition that the reference model of the process system is unknown, this paper proposes a method that can repair consecutive missing values. First, the event logs are divided according to the integrity of the trace, and then the cluster algorithm is applied to complete logs to generate homogeneous trace clusters. Then match the missing trace to the most similar sub log, generate candidate sequences according to the context of the missing part, calculate the context probability of each candidate sequence, and select the one with the highest probability as the repair result. When the number of missing items in the trace is 1, our method has the highest repair accuracy of 97.5 percent in the Small log and 93.3 percent in the real event logs bpic20. Finally, the feasibility of this method is verified on four event logs with different missing ratios and has certain advantages compared with existing methods.},
author = {PDF},
address = {West Yorkshire},
copyright = {2024. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2158-107X},
journal = {International journal of advanced computer science & applications},
keywords = {Algorithms ; Behavior ; Cluster analysis ; Computer science ; Context ; Semantics},
language = {eng},
number = {5},
publisher = {Science and Information (SAI) Organization Limited},
title = {Log Clustering-based Method for Repairing Missing Traces with Context Probability Information},
volume = {15},
year = {2024},
}

@article{cdi_unpaywall_primary_10_5383_juspn_16_02_005,
abstract = {The aim of this paper is to investigate the use of data reduction techniques using distances and areas for monitoring of sensors using process mining approaches. When sensors are used in industrial cases, the real time accumulation of timestamped data tends to pose a problem of storage, processing and analyzing their values in the optimal way possible. Here, the paper tends to present an application of monitoring of sensor signals using reduced parameters from the acquired timestamped values. Each observation is dissected into packets and their attributes such as areas under the curves and successive distances are calculated. The combination of these attributes present real time monitoring scenario for which a blueprint process model can be constructed. This, in turn, helps in identifying signal variations during run-time of the sensor without advanced analysis.},
issn = {1923-7332},
journal = {Journal of Ubiquitous Systems and Pervasive Networks},
language = {eng},
number = {2},
publisher = {International Association for Sharing Knowledge and Sustainability},
title = {Use Cases of Data Reduction to Time Series Data in Sensor Monitoring},
volume = {16},
year = {2022},
}

@article{LuYang2022ADLA,
abstract = {Process mining is a relatively new subject that builds a bridge between traditional process modeling and data mining. Process discovery is one of the most critical parts of process mining, which aims at discovering process models automatically from event logs. Like other data mining techniques, the performance of existing process discovery algorithms can be affected when there are missing activity labels in event logs. In this paper, we assume that the control-flow information in event logs could be useful in repairing missing activity labels. We propose an LSTM-based prediction model, which takes both the prefix and suffix sequences of the events with missing activity labels as input to predict missing activity labels. Additional attributes of event logs are also utilized to improve the performance. Our evaluation of several publicly available datasets shows that the proposed method performed consistently better than existing methods in terms of repairing missing activity labels in event logs.},
author = {Lu, Yang and Chen, Qifan and Poon, Simon K.},
address = {Basel},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
issn = {2078-2489},
journal = {Information (Basel)},
keywords = {Airports ; Algorithms ; Data Accuracy ; Data Management ; Data mining ; Labels ; Machine learning ; Process mining},
language = {eng},
number = {5},
pages = {234-},
publisher = {MDPI AG},
title = {A Deep Learning Approach for Repairing Missing Activity Labels in Event Logs for Process Mining},
volume = {13},
year = {2022},
}

@incollection{TaxNiek2018EAfP,
abstract = {Process mining techniques focus on extracting insight in processes from event logs. In many cases, events recorded in the event log are too fine-grained, causing process discovery algorithms to discover incomprehensible process models or process models that are not representative of the event log. We show that when process discovery algorithms are only able to discover an unrepresentative process model from a low-level event log, structure in the process can in some cases still be discovered by first abstracting the event log to a higher level of granularity. This gives rise to the challenge to bridge the gap between an original low-level event log and a desired high-level perspective on this log, such that a more structured or more comprehensible process model can be discovered. We show that supervised learning can be leveraged for the event abstraction task when annotations with high-level interpretations of the low-level events are available for a subset of the sequences (i.e., traces). We present a method to generate feature vector representations of events based on XES extensions, and describe an approach to abstract events in an event log with Condition Random Fields using these event features. Furthermore, we propose a sequence-focused metric to evaluate supervised event abstraction results that fits closely to the tasks of process discovery and conformance checking. We conclude this paper by demonstrating the usefulness of supervised event abstraction for obtaining more structured and/or more comprehensible process models using both real life event data and synthetic event data.},
author = {Tax, Niek and Sidorova, Natalia and Haakma, Reinder and van der Aalst, Wil M. P. and Bhatia, Rahul and Kapoor, Supriya and Bi, Yaxin and Bhatia, Rahul and Bi, Yaxin and Kapoor, Supriya},
address = {Switzerland},
booktitle = {Proceedings of SAI Intelligent Systems Conference (IntelliSys) 2016},
copyright = {Springer International Publishing AG 2018},
isbn = {3319569937},
issn = {2367-3370},
keywords = {Artificial intelligence ; Process mining},
language = {eng},
pages = {251-269},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Networks and Systems},
title = {Event Abstraction for Process Mining Using Supervised Learning Techniques},
volume = {15},
year = {2018},
}

@incollection{CamargoManuel2022LABP,
abstract = {Business process simulation is a well-known approach to estimate the impact of changes to a process with respect to time and cost measures – a practice known as what-if process analysis. The usefulness of such estimations hinges on the accuracy of the underlying simulation model. Data-Driven Simulation (DDS) methods leverage process mining techniques to learn process simulation models from event logs. Empirical studies have shown that, while DDS models adequately capture the observed sequences of activities and their frequencies, they fail to accurately capture the temporal dynamics of real-life processes. In contrast, generative Deep Learning (DL) models are better able to capture such temporal dynamics. The drawback of DL models is that users cannot alter them for what-if analysis due to their black-box nature. This paper presents a hybrid approach to learn process simulation models from event logs wherein a (stochastic) process model is extracted via DDS techniques, and then combined with a DL model to generate timestamped event sequences. An experimental evaluation shows that the resulting hybrid simulation models match the temporal accuracy of pure DL models, while partially retaining the what-if analysis capability of DDS approaches.},
author = {Camargo, Manuel and Dumas, Marlon and González-Rojas, Oscar},
address = {Cham},
booktitle = {Advanced Information Systems Engineering},
copyright = {The Author(s) 2022, Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.},
isbn = {3031074718},
issn = {0302-9743},
keywords = {Process mining},
language = {eng},
pages = {55-71},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {Learning Accurate Business Process Simulation Models from Event Logs via Automated Process Discovery and Deep Learning},
volume = {13295},
year = {2022},
}

@incollection{FongerFrederik2023MTDo,
abstract = {The combination of machine learning techniques with process analytics like process mining might significantly elevate novel insights into time-series data collections that are predominantly used in disciplines like life and natural science. To efficiently analyse time-series data by process mining requires bridging several challenges. For instance, time-series data need to be processed and represented in a useable form to turn into information. This paper provides: (1) A structured approach to map time-series data on control-flow patterns that we annotated for our purpose. (2) Based on the simulation of the patterns it is possible to generate synthetic data in varying quality, which is again a crucial step for accurate results from machine learning techniques. In this way, our approach contributes understanding novel insights in terms of causal-effects in time-series data, which could not be answered by traditional approaches used in the disciplines.},
author = {Fonger, Frederik and Aleknonytė-Resch, Milda and Koschmider, Agnes and Ruiz, Marcela and Soffer, Pnina and Ruiz, Marcela and Soffer, Pnina},
address = {Switzerland},
booktitle = {Advanced Information Systems Engineering Workshops},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2023},
isbn = {9783031349843},
issn = {1865-1348},
keywords = {Process mining},
language = {eng},
pages = {50-61},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Mapping Time-Series Data on Process Patterns to Generate Synthetic Data},
volume = {482},
year = {2023},
}

@incollection{HerbertTobias2021GRPE,
abstract = {Domains such as manufacturing and medicine crave for continuous monitoring and analysis of their processes, especially in combination with time series as produced by sensors. Time series data can be exploited to, for example, explain and predict concept drifts during runtime. Generally, a certain data volume is required in order to produce meaningful analysis results. However, reliable data sets are often missing, for example, if event streams and times series data are collected separately, in case of a new process, or if it is too expensive to obtain a sufficient data volume. Additional challenges arise with preparing time series data from multiple event sources, variations in data collection frequency, and concept drift. This paper proposes the GENLOG approach to generate reliable event and time series data that follows the distribution of the underlying input data set. GENLOG employs data resampling and enables the user to select different parts of the log data to orchestrate the training of a recurrent neural network for stream generation. The generated data is sampled back to its original sample rate and is embedded into the originating log data file. Overall, GENLOG can boost small data sets and consequently the application of online process mining.},
author = {Herbert, Tobias and Mangler, Juergen and Rinderle-Ma, Stefanie and Gill, Asif and Nurcan, Selmin and Schmidt, Rainer and Augusto, Adriano and Zdravkovic, Jelena and Reinhartz-Berger, Iris and Gill, Asif and Nurcan, Selmin and Augusto, Adriano and Reinhartz-Berger, Iris and Schmidt, Rainer and Zdravkovic, Jelena},
address = {Switzerland},
booktitle = {Enterprise, Business-Process and Information Systems Modeling},
copyright = {Springer Nature Switzerland AG 2021},
isbn = {9783030791858},
issn = {1865-1348},
language = {eng},
pages = {81-95},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Generating Reliable Process Event Streams and Time Series Data Based on Neural Networks},
volume = {421},
year = {2021},
}

@incollection{RebmannAdrian2019EtDo,
abstract = {The analysis of business processes using process mining requires structured log data. Regarding manual activities, this data can be generated from sensor data acquired from the Internet of Things. The main objective of this paper is the development and evaluation of an approach which recognizes and logs manually performed activities, enabling the application of established process discovery methods. A system was implemented which uses a body area network, image data of the process environment and feedback from the executing workers in case of uncertainties during detection. Both feedback and image data are acquired and processed during process execution. In a case study in a laboratory environment, the system was evaluated using an example process. The implemented approach shows that the inclusion of image data of the environment and user feedback in ambiguous situations during recognition generate log data which well represent actual process behavior.},
author = {Rebmann, Adrian and Emrich, Andreas and Fettke, Peter and Zdun, Uwe and Dijkman, Remco and Di Francescomarino, Chiara and Di Francescomarino, Chiara and Zdun, Uwe and Dijkman, Remco},
address = {Switzerland},
booktitle = {Business Process Management Workshops},
copyright = {Springer Nature Switzerland AG 2019},
isbn = {3030374521},
issn = {1865-1348},
keywords = {Human activity recognition},
language = {eng},
pages = {130-141},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Business Information Processing},
title = {Enabling the Discovery of Manual Processes Using a Multi-modal Activity Recognition Approach},
volume = {362},
year = {2019},
}

@inproceedings{TelloGhalia2019MLFf,
abstract = {Real-life event logs are typically much less structured and more complex than the predefined business activities they refer to. Most of the existing process mining techniques assume that there is a one-to-one mapping between process model activities and events recorded during process execution. Unfortunately, event logs and process model activities are defined at different levels of granularity. The challenges posed by this discrepancy can be addressed by means of log-lifting. In this work we develop a machine-learning-based framework aimed at bridging the abstraction level gap between logs and process models. The proposed framework operates of two main phases: log segmentation and machine-learning-based classification. The purpose of the segmentation phase is to identify the potential segment separators in a flow of low-level events, in which each segment corresponds to an unknown high-level activity. For this, we propose a segmentation algorithm based on maximum likelihood with n-gram analysis. In the second phase, event segments are mapped into their corresponding high-level activities using a supervised machine learning technique. Several machine learning classification methods are explored including ANNs, SVMs, and random forest. We demonstrate the applicability of our framework using a real-life event log provided by the SAP company. The results obtained show that a machine learning approach based on the random forest algorithm outperforms the other methods with an accuracy of 96.4%. The testing time was found to be around 0.01s, which makes the algorithm a good candidate for real-time deployment scenarios.},
author = {Tello, Ghalia and Gianini, Gabriele and Mizouni, Rabeb and Damiani, Ernesto and Mendling, Jan and Röglinger, Maximilian and van Dongen, Boudewijn F. and Hildebrandt, Thomas},
address = {Cham},
booktitle = {Business Process Management},
copyright = {Springer Nature Switzerland AG 2019},
isbn = {9783030266189},
issn = {0302-9743},
keywords = {Machine learning ; Process mining},
language = {eng},
pages = {232-249},
publisher = {Springer International Publishing},
title = {Machine Learning-Based Framework for Log-Lifting in Business Process Mining Applications},
volume = {11675},
year = {2019},
}

@article{LiKeyi2024PGPT,
abstract = {Process data constructed from event logs provides valuable insights into procedural dynamics over time. The confidential information in process data, together with the data’s intricate nature, makes the datasets not sharable and challenging to collect. Consequently, research is limited using process data and analytics in the process mining domain. In this study, we introduced a synthetic process data generation task to address the limitation of sharable process data. We introduced a generative adversarial network, called ProcessGAN, to generate process data with activity sequences and corresponding timestamps. ProcessGAN consists of a transformer-based network as the generator, and a time-aware self-attention network as the discriminator. It can generate privacy-preserving process data from random noise. ProcessGAN considers the duration of the process and time intervals between activities to generate realistic activity sequences with timestamps. We evaluated ProcessGAN on five real-world datasets, two that are public and three collected in medical domains that are private. To evaluate the synthetic data, in addition to statistical metrics, we trained a supervised model to score the synthetic processes. We also used process mining to discover workflows for synthetic medical processes and had domain experts evaluate the clinical applicability of the synthetic workflows. ProcessGAN outperformed the existing generative models in generating complex processes with valid parallel pathways. The synthetic process data generated by ProcessGAN better represented the long-range dependencies between activities, a feature relevant to complicated medical and other processes. The timestamps generated by the ProcessGAN model showed similar distributions with the authentic timestamps. In addition, we trained a transformer-based network to generate synthetic contexts (e.g., patient demographics) that were associated with the synthetic processes. The synthetic contexts generated by our model outperformed the baseline models, with the distributions similar to the authentic contexts. We conclude that ProcessGAN can generate sharable synthetic process data indistinguishable from authentic data. Our source code is available in https://github.com/raaachli/ProcessGAN.},
author = {Li, Keyi and Yang, Sen and Sullivan, Travis M. and Burd, Randall S. and Marsic, Ivan},
address = {New York, NY},
copyright = {Copyright held by the owner/author(s).},
issn = {1556-4681},
journal = {ACM transactions on knowledge discovery from data},
keywords = {Artificial intelligence ; Computer science ; Data mining ; High performance computing ; Information storage and retrieval systems ; Technology},
language = {eng},
number = {9},
pages = {1-31},
publisher = {ACM},
title = {ProcessGAN: Generating Privacy-Preserving Time-Aware Process Data with Conditional Generative Adversarial Nets},
volume = {18},
year = {2024},
}

@incollection{SeeligerAlexander2024IMEL,
abstract = {Market forces such as rising amounts of product variants and decreasing batch sizes lead to higher complexity in manufacturing processes. Therefore, production management’s demand for data-based process transparency is growing continuously as well as the number of companies turning to process mining to address these challenges. Information systems in production usually do not provide readily available event log data for the analysis. This paper investigates several techniques for inferring missing event log data in production processes by extracting events with timestamps from sensor data from machines and link them to process instances. We demonstrate the effectiveness of our approach in a real-world manufacturing environment. The evaluation of the resulting event logs revealed that the quality of the timestamps and the assignment of the actual process instances is sufficient to apply process mining techniques that would have required both greater effort and higher cost intensity if a traceability system had been implemented.},
author = {Seeliger, Alexander and Schreiber, Markus and Giger, Florian and Metternich, Joachim and Mühlhäuser, Max and Jans, Mieke and Rosemann, Michael and Resinas, Manuel and Marrella, Andrea and Marrella, Andrea and Jans, Mieke and Rosemann, Michael and Resinas, Manuel},
address = {Switzerland},
booktitle = {Business Process Management Forum},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2024},
isbn = {9783031704178},
issn = {1865-1348},
keywords = {Internet of things ; Process mining},
language = {eng},
pages = {232-248},
publisher = {Springer},
series = {Lecture Notes in Business Information Processing},
title = {Inferring Missing Event Log Data from IoT Sensor Data - A Case Study in Manufacturing},
volume = {526},
year = {2024},
}

@inproceedings{vanEckMaikelL.2016Epmo,
abstract = {In this paper we address the challenge of applying process mining to discover models of human behaviour from sensor data. This challenge is caused by a gap between sensor data and the event logs that are used as input for process mining techniques, so we provide a transformation approach to bridge this gap. As a result, besides the automatic discovery of process models, the transformed sensor data can also be used by various other process mining techniques, e.g. to identify differences between observed behaviour and expected behaviour. We discuss the transformation approach in the context of the design process of smart products and related services, using a case study performed at Philips where a smart baby bottle has been developed. This case study also demonstrates that the use of process mining can add value to the smart product design process.},
author = {van Eck, Maikel L. and Sidorova, Natalia and van der Aalst, Wil M. P.},
booktitle = {2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)},
isbn = {1479987107},
issn = {2151-1357},
keywords = {Context ; Data mining ; Process mining ; Product design ; Time measurements},
language = {eng},
pages = {1-12},
publisher = {IEEE},
title = {Enabling process mining on sensor data from smart products},
year = {2016},
}

@incollection{AppiceAnnalisa2016DaTO,
abstract = {The goal of process mining is to extract process-related information by observing events recorded in event logs. An event is an activity initiated or completed by a resource at a certain time point. Organizational mining is a subfield of process mining that focuses on the organizational perspective of a business process. It considers the resource attribute and derives a profile that characterizes the behavior of a resource in a specific business process. By relating resources associated with correlated profiles, it is possible to define a social network. This paper focuses on the idea of performing organizational mining of event logs via social network mining. It presents a framework that resorts to a stream representation of an event log. It adapts the time-based window model to process this stream, so that window-based social resource networks can be constructed, in order to represent interactions between resources operating at the data window level. Finally, it integrates specific algorithms, in order to discover (overlapping) communities of resources and track the evolution of these communities over consecutive windows. This paper applies the defined framework to two real event logs.},
author = {Appice, Annalisa and Di Pietro, Marco and Greco, Claudio and Malerba, Donato and Manco, Giuseppe and Masciari, Elio and Ras, Zbigniew W and Loglisci, Corrado and Ceci, Michelangelo and Ceci, Michelangelo and Ras, Zbigniew W. and Manco, Giuseppe and Loglisci, Corrado and Masciari, Elio},
address = {Switzerland},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
copyright = {Springer International Publishing Switzerland 2016},
isbn = {3319393146},
issn = {0302-9743},
keywords = {Data mining},
language = {eng},
pages = {46-60},
publisher = {Springer International Publishing AG},
series = {Lecture Notes in Computer Science},
title = {Discovering and Tracking Organizational Structures in Event Logs},
volume = {9607},
year = {2016},
}

@INPROCEEDINGS{10680661,
  author={Zhou, Johnson and Armas-Cervantes, Abel and Bozorgi, Zahra Dasht and Otte, Ellen and Polyvyanyy, Artem},
  booktitle={2024 6th International Conference on Process Mining (ICPM)}, 
  title={Discovering Changes in Cell Stability Using Process Mining: A Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={65-72},
  keywords={Process mining;Production;Transforms;Companies;Predictive models;Monoclonal antibodies;Stability analysis;Monitoring;Chemicals;Pharmaceuticals;bioprocess development;seed train performance insights;process mining},
  doi={10.1109/ICPM63005.2024.10680661}}
